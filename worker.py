# ==============================
# worker.py (Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ÙƒØ§Ù…Ù„ Ù…Ø¹ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª)
# ==============================
import os
import asyncio
import re
import sys
import logging
import unicodedata
from collections import defaultdict
from datetime import datetime
from telethon import TelegramClient, events, types
from telethon.sessions import StringSession
from telethon.tl.functions.messages import ImportChatInviteRequest
from sqlalchemy import create_engine, text
from sqlalchemy.exc import SQLAlchemyError

# ------------------------------
# Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
# ------------------------------
API_ID = int(os.environ.get("API_ID", 0))
API_HASH = os.environ.get("API_HASH", "")
CHANNELS = os.environ.get("CHANNELS", "https://t.me/ShoofFilm,https://t.me/shoofcima")
DATABASE_URL = os.environ.get("DATABASE_URL", "")
STRING_SESSION = os.environ.get("STRING_SESSION", "")
IMPORT_HISTORY = os.environ.get("IMPORT_HISTORY", "false").lower() == "true"
CHECK_DELETED_MESSAGES = os.environ.get("CHECK_DELETED_MESSAGES", "true").lower() == "true"
DEBUG_MODE = os.environ.get("DEBUG_MODE", "false").lower() == "true"
RESET_DATABASE = os.environ.get("RESET_DATABASE", "false").lower() == "true"
SYNC_LIMIT = int(os.environ.get("SYNC_LIMIT", "10000"))  # 0 = ØºÙŠØ± Ù…Ø­Ø¯ÙˆØ¯
MOVIE_THRESHOLD = int(os.environ.get("MOVIE_THRESHOLD", "3"))   # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¹Ø¯Ø¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª <= Ù‡Ø°Ø§ Ø§Ù„Ø±Ù‚Ù…ØŒ ÙÙŠÙ„Ù…
SERIES_THRESHOLD = int(os.environ.get("SERIES_THRESHOLD", "5")) # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¹Ø¯Ø¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª >= Ù‡Ø°Ø§ Ø§Ù„Ø±Ù‚Ù…ØŒ Ù…Ø³Ù„Ø³Ù„

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.DEBUG if DEBUG_MODE else logging.INFO
)
logger = logging.getLogger(__name__)

if not all([API_ID, API_HASH, DATABASE_URL, STRING_SESSION]):
    logger.error("âŒ Ù…ØªØºÙŠØ±Ø§Øª Ù…ÙÙ‚ÙˆØ¯Ø©")
    sys.exit(1)

if DATABASE_URL.startswith("postgres://"):
    DATABASE_URL = DATABASE_URL.replace("postgres://", "postgresql://", 1)

CHANNEL_LIST = [chan.strip() for chan in CHANNELS.split(',') if chan.strip()]

# ------------------------------
# Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¹ÙŠÙŠÙ† Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
# ------------------------------
try:
    engine = create_engine(DATABASE_URL)
    with engine.connect() as conn:
        conn.execute(text("SELECT 1"))
    logger.info("âœ… Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

    if RESET_DATABASE:
        logger.warning("âš ï¸ Ø¬Ø§Ø±ÙŠ Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
        with engine.begin() as conn:
            conn.execute(text("DROP SCHEMA public CASCADE"))
            conn.execute(text("CREATE SCHEMA public"))
        logger.info("âœ… ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
except Exception as e:
    logger.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
    sys.exit(1)

# ------------------------------
# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
# ------------------------------
with engine.begin() as conn:
    conn.execute(text("""
        CREATE TABLE IF NOT EXISTS series (
            id SERIAL PRIMARY KEY,
            name VARCHAR(255) NOT NULL,
            type VARCHAR(10) DEFAULT 'series',
            normalized_name VARCHAR(255),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """))
    conn.execute(text("""
        CREATE TABLE IF NOT EXISTS episodes (
            id SERIAL PRIMARY KEY,
            series_id INTEGER REFERENCES series(id),
            season INTEGER DEFAULT 1,
            episode_number INTEGER NOT NULL,
            telegram_message_id INTEGER UNIQUE NOT NULL,
            telegram_channel_id VARCHAR(255),
            added_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """))
    conn.execute(text("""
        CREATE TABLE IF NOT EXISTS channel_context (
            channel_id VARCHAR(255) PRIMARY KEY,
            series_name VARCHAR(255) NOT NULL,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """))
    conn.execute(text("CREATE INDEX IF NOT EXISTS idx_series_normalized_name ON series(normalized_name)"))
    conn.execute(text("CREATE UNIQUE INDEX IF NOT EXISTS idx_episodes_msg_id ON episodes(telegram_message_id)"))
    conn.execute(text("CREATE INDEX IF NOT EXISTS idx_episodes_channel_id ON episodes(telegram_channel_id)"))
    conn.execute(text("CREATE INDEX IF NOT EXISTS idx_episodes_added_at ON episodes(added_at)"))
logger.info("âœ… Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø¬Ø§Ù‡Ø²Ø©")

# ------------------------------
# Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ ÙˆØ§Ù„ØªØ·Ø¨ÙŠØ¹
# ------------------------------
def normalize_arabic(text):
    if not text:
        return ''
    text = unicodedata.normalize('NFKD', text)
    text = re.sub(r'[\u064B-\u065F]', '', text)  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„
    text = text.replace('Ø¥', 'Ø§').replace('Ø£', 'Ø§').replace('Ø¢', 'Ø§').replace('Ù‰', 'Ø§')
    text = text.replace('Ø©', 'Ù‡')
    return text

def normalize_series_name(name):
    if not name:
        return ''
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¯Ø®ÙŠÙ„Ø© Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© ÙˆØ§Ù„Ù†Ù‡Ø§ÙŠØ©
    name = re.sub(r'^(Ù…Ø³Ù„Ø³Ù„|ÙÙŠÙ„Ù…)\s+', '', name, flags=re.UNICODE)
    name = re.sub(r'\s+(Ø§Ù„Ø­Ù„Ù‚Ø©|Ø§Ù„Ù…ÙˆØ³Ù…|Ø§Ù„Ø¬Ø²Ø¡)$', '', name, flags=re.UNICODE)
    name = re.sub(r'\s+\d+$', '', name)
    name = normalize_arabic(name)
    name = re.sub(r'\s+', ' ', name).strip().lower()
    return name

def clean_name_for_series(name):
    name = re.sub(r'^Ù…Ø³Ù„Ø³Ù„\s+', '', name, flags=re.UNICODE)
    name = re.sub(r'\s+(Ø§Ù„Ø­Ù„Ù‚Ø©|Ø§Ù„Ù…ÙˆØ³Ù…)$', '', name, flags=re.UNICODE)
    name = re.sub(r'\s+\d+$', '', name)
    name = re.sub(r'\s+', ' ', name).strip()
    return name

def clean_name_for_movie(name):
    name = re.sub(r'^ÙÙŠÙ„Ù…\s+', '', name, flags=re.UNICODE)
    name = re.sub(r'\s+Ø§Ù„Ø¬Ø²Ø¡\s*\d*$', '', name, flags=re.UNICODE)
    name = re.sub(r'\s+\d+$', '', name)
    name = re.sub(r'\s+', ' ', name).strip()
    return name

# ------------------------------
# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„Ø³ÙŠØ§Ù‚
# ------------------------------
def load_channel_context():
    context = {}
    try:
        with engine.connect() as conn:
            rows = conn.execute(text("SELECT channel_id, series_name FROM channel_context")).fetchall()
            for row in rows:
                context[row[0]] = row[1]
        logger.info(f"ğŸ“‚ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø³ÙŠØ§Ù‚ {len(context)} Ù‚Ù†Ø§Ø© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    except Exception as e:
        logger.error(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚: {e}")
    return context

def save_channel_context(channel_id, series_name):
    try:
        with engine.begin() as conn:
            conn.execute(
                text("""
                    INSERT INTO channel_context (channel_id, series_name)
                    VALUES (:chan, :name)
                    ON CONFLICT (channel_id) DO UPDATE SET series_name = :name, updated_at = CURRENT_TIMESTAMP
                """),
                {"chan": channel_id, "name": series_name}
            )
        logger.debug(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø³ÙŠØ§Ù‚ Ù„Ù„Ù‚Ù†Ø§Ø© {channel_id}: {series_name}")
    except Exception as e:
        logger.error(f"âŒ ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ø³ÙŠØ§Ù‚: {e}")

# ------------------------------
# Ø¯Ø§Ù„Ø© Ù…ØªØ·ÙˆØ±Ø© Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
# ------------------------------
def has_video_media(msg):
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø±Ø³Ø§Ù„Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙÙŠØ¯ÙŠÙˆ Ø­Ù‚ÙŠÙ‚ÙŠ"""
    if msg.video:
        return True
    if msg.document:
        mime = msg.document.mime_type or ''
        if mime.startswith('video/'):
            return True
        if msg.document.attributes:
            for attr in msg.document.attributes:
                if isinstance(attr, types.DocumentAttributeFilename):
                    ext = os.path.splitext(attr.file_name)[-1].lower()
                    if ext in ['.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.webm', '.m4v', '.3gp']:
                        return True
                elif isinstance(attr, types.DocumentAttributeVideo):
                    return True
        if msg.document.size > 5 * 1024 * 1024 and 'octet-stream' in mime:
            return True
    if msg.media and hasattr(msg.media, 'document'):
        doc = msg.media.document
        mime = doc.mime_type or ''
        if mime.startswith('video/'):
            return True
        for attr in doc.attributes:
            if isinstance(attr, types.DocumentAttributeFilename):
                ext = os.path.splitext(attr.file_name)[-1].lower()
                if ext in ['.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.webm', '.m4v', '.3gp']:
                    return True
            elif isinstance(attr, types.DocumentAttributeVideo):
                return True
        if doc.size > 5 * 1024 * 1024 and 'octet-stream' in mime:
            return True
    return False

# ------------------------------
# Ø¯Ø§Ù„Ø© Ù„ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ ÙˆØ¹Ø¯Ø¯ Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
# ------------------------------
def determine_content_type(name, existing_count=0):
    """
    ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰:
    - ÙˆØ¬ÙˆØ¯ ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© ÙÙŠ Ø§Ù„Ø§Ø³Ù… (Ù…Ø³Ù„Ø³Ù„ØŒ ÙÙŠÙ„Ù…ØŒ Ø§Ù„Ù…ÙˆØ³Ù…ØŒ Ø§Ù„Ø­Ù„Ù‚Ø©ØŒ Ø§Ù„Ø¬Ø²Ø¡)
    - Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹ Ù„Ù‡Ø°Ø§ Ø§Ù„Ø§Ø³Ù…
    """
    lower_name = name.lower()
    # ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ù„Ù…Ø³Ù„Ø³Ù„
    series_keywords = ['Ù…Ø³Ù„Ø³Ù„', 'Ø§Ù„Ø­Ù„Ù‚Ø©', 'Ø§Ù„Ù…ÙˆØ³Ù…', 'Ø­Ù„Ù‚Ø©', 'Ù…ÙˆØ³Ù…']
    # ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ù„ÙÙŠÙ„Ù…
    movie_keywords = ['ÙÙŠÙ„Ù…', 'Ø§Ù„Ø¬Ø²Ø¡', 'Ø¬Ø²Ø¡']

    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ ÙƒÙ„Ù…Ø§Øª ØµØ±ÙŠØ­Ø©
    has_series_word = any(kw in lower_name for kw in series_keywords)
    has_movie_word = any(kw in lower_name for kw in movie_keywords)

    if has_series_word and not has_movie_word:
        return 'series'
    if has_movie_word and not has_series_word:
        return 'movie'

    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª ØºÙŠØ± Ø­Ø§Ø³Ù…Ø©ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
    if existing_count >= SERIES_THRESHOLD:
        return 'series'
    elif existing_count <= MOVIE_THRESHOLD:
        return 'movie'
    else:
        # ÙÙŠ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø±Ù…Ø§Ø¯ÙŠØ© (4-5 Ø­Ù„Ù‚Ø§Øª) Ù†ÙØ¶Ù„ Ø§Ù„Ù…Ø³Ù„Ø³Ù„
        return 'series'

# ------------------------------
# Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠØ©
# ------------------------------
def parse_content_info(msg_text, channel_id, has_video, existing_count=0):
    """
    ØªØ­Ù„ÙŠÙ„ Ù†Øµ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØ±Ù‚Ù… Ø§Ù„Ù…ÙˆØ³Ù… ÙˆØ§Ù„Ø­Ù„Ù‚Ø©.
    ØªØ¹ÙŠØ¯ (name, content_type, season, episode) Ø£Ùˆ (None, None, None, None) Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ ÙÙŠØ¯ÙŠÙˆ.
    """
    if not msg_text or not has_video:
        return None, None, None, None

    original_text = msg_text.strip()
    text = original_text

    logger.debug(f"Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù„ÙŠÙ„: {original_text[:100]}")

    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
    common_prefixes = ['Ù…Ø´Ø§Ù‡Ø¯Ø©', 'ØªØ­Ù…ÙŠÙ„', 'Ø§Ù„Ø¢Ù†', 'Ù…Ø³Ù„Ø³Ù„', 'ÙÙŠÙ„Ù…', 'Ø´Ø§Ù‡Ø¯', 'Ù…ØªØ±Ø¬Ù…', 'Ø­Ù„Ù‚Ø©', 'Ø§Ù„Ù…Ø³Ù„Ø³Ù„']
    for prefix in common_prefixes:
        if text.startswith(prefix):
            text = text[len(prefix):].strip()
            text = re.sub(r'^[\s:-]+', '', text)

    season = 1
    episode = 1
    name = text
    content_type = 'movie'  # Ù…Ø¤Ù‚Øª

    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ³Ù… ÙˆØ§Ù„Ø­Ù„Ù‚Ø© Ø¨Ø£Ù†Ù…Ø§Ø· Regex
    patterns = [
        (r'^(.*?)\s*[Ss](\d+)[Ee](\d+)$', lambda m: (m.group(1).strip(), int(m.group(2)), int(m.group(3)))),
        (r'^(.*?)\s*[Ss](\d+)[Ee](\d+)', lambda m: (m.group(1).strip(), int(m.group(2)), int(m.group(3)))),
        (r'(.*?)\s*Ø§Ù„Ù…ÙˆØ³Ù…\s*[:_-]?\s*(\d+)\s*Ø§Ù„Ø­Ù„Ù‚Ø©\s*[:_-]?\s*(\d+)', lambda m: (m.group(1).strip(), int(m.group(2)), int(m.group(3)))),
        (r'(.*?)\s*Ø§Ù„Ø­Ù„Ù‚Ø©\s*[:_-]?\s*(\d+)\s*Ù…Ù†\s*Ø§Ù„Ù…ÙˆØ³Ù…\s*[:_-]?\s*(\d+)', lambda m: (m.group(1).strip(), int(m.group(3)), int(m.group(2)))),
        (r'(.*?)\s*Ø§Ù„Ù…ÙˆØ³Ù…\s*[:_-]?\s*(\d+)\s*-\s*(\d+)', lambda m: (m.group(1).strip(), int(m.group(2)), int(m.group(3)))),
        (r'(.*?)\s*Ù…(\d+)\s*Ø­(\d+)', lambda m: (m.group(1).strip(), int(m.group(2)), int(m.group(3)))),
        (r'(.*?)\s*Ø§Ù„Ø­Ù„Ù‚Ø©\s*[:_-]?\s*(\d+)', lambda m: (m.group(1).strip(), 1, int(m.group(2)))),
        (r'^(.*?)\s+(\d+)[-\s]+(\d+)$', lambda m: (m.group(1).strip(), int(m.group(2)), int(m.group(3)))),
        (r'^(.*?)\s+(\d+)$', lambda m: (m.group(1).strip(), 1, int(m.group(2)))),
        (r'(.*?)\s*Ø§Ù„Ø¬Ø²Ø¡\s*[:_-]?\s*(\d+)', lambda m: (m.group(1).strip(), int(m.group(2)), 1)),
    ]

    for pattern, extractor in patterns:
        match = re.search(pattern, text, re.UNICODE)
        if match:
            try:
                name, season, episode = extractor(match)
                # Ø¥Ø°Ø§ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Ù…Ø·ØŒ ÙÙ‡Ùˆ Ù…Ø³Ù„Ø³Ù„ ØºØ§Ù„Ø¨Ø§Ù‹
                content_type = 'series'
                logger.debug(f"Ù†Ù…Ø· Ù…Ø·Ø§Ø¨Ù‚: {pattern} -> {name} Ù…{season} Ø­{episode}")
                break
            except:
                continue

    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø§Ø³Ù…
    name = re.sub(r'\s+', ' ', name).strip()
    name = re.sub(r'\s+\d+$', '', name)  # Ø¥Ø²Ø§Ù„Ø© Ø£Ø±Ù‚Ø§Ù… Ø²Ø§Ø¦Ø¯Ø©

    if not name:
        name = original_text[:200]

    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†ÙˆØ¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
    content_type = determine_content_type(name, existing_count)

    logger.debug(f"Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„: '{original_text[:50]}...' -> {name}, {content_type}, S{season}E{episode}")
    return name, content_type, season, episode

# ------------------------------
# Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù‚Ù†ÙˆØ§Øª
# ------------------------------
async def get_channel_entity(client, channel_input):
    try:
        return await client.get_entity(channel_input)
    except Exception as e:
        logger.warning(f"âš ï¸ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ÙˆØµÙˆÙ„ {channel_input}: {e}")
        if isinstance(channel_input, str) and channel_input.startswith('https://t.me/+'):
            try:
                invite = channel_input.split('+')[-1]
                await client(ImportChatInviteRequest(invite))
                return await client.get_entity(channel_input)
            except:
                return None
        return None

def get_existing_episode_count(name, content_type=None):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ù„Ø§Ø³Ù… Ù…Ø¹ÙŠÙ† (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… normalized_name)"""
    try:
        normalized = normalize_series_name(name)
        with engine.connect() as conn:
            row = conn.execute(
                text("SELECT id FROM series WHERE normalized_name = :norm"),
                {"norm": normalized}
            ).fetchone()
            if row:
                count = conn.execute(
                    text("SELECT COUNT(*) FROM episodes WHERE series_id = :sid"),
                    {"sid": row[0]}
                ).scalar()
                return count
        return 0
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ get_existing_episode_count: {e}")
        return 0

def save_to_database(name, content_type, season, episode, msg_id, channel_id):
    try:
        normalized = normalize_series_name(name)
        with engine.begin() as conn:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø³Ù„Ø³Ù„ Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ù†ÙØ³ normalized_name
            row = conn.execute(
                text("SELECT id FROM series WHERE normalized_name = :norm AND type = :typ"),
                {"norm": normalized, "typ": content_type}
            ).fetchone()
            if not row:
                # Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹ Ø¨Ù†ÙˆØ¹ Ù…Ø®ØªÙ„ÙØŒ Ù†Ø­Ø§ÙˆÙ„ Ø§Ù„Ø¨Ø­Ø« Ø¨Ø¯ÙˆÙ† Ù†ÙˆØ¹
                row = conn.execute(
                    text("SELECT id, type FROM series WHERE normalized_name = :norm"),
                    {"norm": normalized}
                ).fetchone()
                if row:
                    # Ø¥Ø°Ø§ ÙˆØ¬Ø¯ Ø¨Ù†ÙˆØ¹ Ù…Ø®ØªÙ„ÙØŒ Ù‚Ø¯ Ù†Ø­ØªØ§Ø¬ Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†ÙˆØ¹ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ØªØ¶Ø§Ø±Ø¨
                    # Ø³Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø£ÙƒØ«Ø± Ø¯Ù‚Ø© (Ù…Ø«Ù„Ø§Ù‹ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù‚Ø¯ÙŠÙ… movie ÙˆØ§Ù„Ø¬Ø¯ÙŠØ¯ series)
                    old_type = row[1]
                    if old_type != content_type:
                        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù‚Ø¯ÙŠÙ… movie ÙˆØ§Ù„Ø¬Ø¯ÙŠØ¯ series (Ø£Ùˆ Ø§Ù„Ø¹ÙƒØ³) Ù†Ø®ØªØ§Ø± Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹
                        # Ù‡Ù†Ø§ Ù†Ø¹Ø·ÙŠ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ù„Ù€ series Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ù„Ù‚Ø§Øª ÙƒØ¨ÙŠØ±Ø§Ù‹
                        existing_count = conn.execute(
                            text("SELECT COUNT(*) FROM episodes WHERE series_id = :sid"),
                            {"sid": row[0]}
                        ).scalar()
                        if content_type == 'series' and existing_count >= SERIES_THRESHOLD:
                            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†ÙˆØ¹
                            conn.execute(
                                text("UPDATE series SET type = :typ WHERE id = :sid"),
                                {"typ": content_type, "sid": row[0]}
                            )
                            logger.info(f"ğŸ”„ ØªØ­Ø¯ÙŠØ« Ù†ÙˆØ¹ {name} Ù…Ù† {old_type} Ø¥Ù„Ù‰ {content_type}")
                        # Ù†Ø³ØªØ®Ø¯Ù… Ù†ÙØ³ Ø§Ù„Ù€ id
                        row = (row[0],)
                else:
                    # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙŠØ¯
                    row = conn.execute(
                        text("INSERT INTO series (name, normalized_name, type) VALUES (:name, :norm, :typ) RETURNING id"),
                        {"name": name, "norm": normalized, "typ": content_type}
                    ).fetchone()
            sid = row[0]

            # Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„Ø­Ù„Ù‚Ø©
            inserted = conn.execute(
                text("""
                    INSERT INTO episodes (series_id, season, episode_number, telegram_message_id, telegram_channel_id)
                    VALUES (:sid, :season, :ep, :msg, :chan)
                    ON CONFLICT (telegram_message_id) DO NOTHING
                    RETURNING id
                """),
                {"sid": sid, "season": season, "ep": episode, "msg": msg_id, "chan": channel_id}
            ).fetchone()
            if inserted:
                logger.info(f"âœ… Ø¬Ø¯ÙŠØ¯: {name} - Ù…{season} Ø­{episode} Ù…Ù† {channel_id}")
                return True
            else:
                logger.debug(f"âš ï¸ Ù…ÙˆØ¬ÙˆØ¯Ø©: {msg_id}")
                return False
    except Exception as e:
        logger.exception(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ÙØ¸ Ù„Ù„Ø±Ø³Ø§Ù„Ø© {msg_id}: {e}")
        return False

def delete_from_database(msg_id):
    try:
        with engine.begin() as conn:
            ep = conn.execute(
                text("SELECT series_id FROM episodes WHERE telegram_message_id = :msg"),
                {"msg": msg_id}
            ).fetchone()
            if not ep:
                return False
            sid = ep[0]
            conn.execute(text("DELETE FROM episodes WHERE telegram_message_id = :msg"), {"msg": msg_id})
            remaining = conn.execute(
                text("SELECT COUNT(*) FROM episodes WHERE series_id = :sid"),
                {"sid": sid}
            ).scalar()
            if remaining == 0:
                conn.execute(text("DELETE FROM series WHERE id = :sid"), {"sid": sid})
                logger.info(f"ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ø³Ù„Ø³Ù„ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ (Ø¢Ø®Ø± Ø­Ù„Ù‚Ø© {msg_id})")
            else:
                logger.info(f"ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ø­Ù„Ù‚Ø© {msg_id}")
            return True
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­Ø°Ù: {e}")
        return False

def clean_orphan_series():
    try:
        with engine.begin() as conn:
            result = conn.execute(text("""
                DELETE FROM series
                WHERE id NOT IN (SELECT DISTINCT series_id FROM episodes)
                RETURNING id, name, type
            """)).fetchall()
            if result:
                for r in result:
                    logger.info(f"ğŸ§¹ ØªÙ… Ø­Ø°Ù {r[2]} Ø¨Ø¯ÙˆÙ† Ø­Ù„Ù‚Ø§Øª: {r[1]} (ID: {r[0]})")
                logger.info(f"âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ {len(result)} Ù…Ø³Ù„Ø³Ù„/ÙÙŠÙ„Ù… Ø¨Ø¯ÙˆÙ† Ø­Ù„Ù‚Ø§Øª")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„ÙŠØªÙŠÙ…Ø©: {e}")

def fix_misclassified_series():
    try:
        with engine.begin() as conn:
            rows = conn.execute(text("""
                SELECT s.id, s.name, COUNT(e.id) as ep_count
                FROM series s
                JOIN episodes e ON s.id = e.series_id
                WHERE s.type = 'movie'
                GROUP BY s.id, s.name
                HAVING COUNT(e.id) > 1
            """)).fetchall()
            if rows:
                for row in rows:
                    sid, name, count = row
                    conn.execute(
                        text("UPDATE series SET type = 'series' WHERE id = :sid"),
                        {"sid": sid}
                    )
                    logger.info(f"ğŸ”„ ØªÙ… ØªØµØ­ÙŠØ­ {name} (ID: {sid}) Ù…Ù† ÙÙŠÙ„Ù… Ø¥Ù„Ù‰ Ù…Ø³Ù„Ø³Ù„ (Ù„Ø¯ÙŠÙ‡ {count} Ø­Ù„Ù‚Ø§Øª)")
                logger.info(f"âœ… ØªÙ… ØªØµØ­ÙŠØ­ {len(rows)} Ù…Ø³Ù„Ø³Ù„ ÙƒØ§Ù† Ù…ØµÙ†Ù Ø®Ø·Ø£ ÙƒÙÙŠÙ„Ù…")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØµØ­ÙŠØ­ Ø§Ù„ØªØµÙ†ÙŠÙ: {e}")

# ------------------------------
# Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù‚Ù†ÙˆØ§Øª
# ------------------------------
async def sync_channel_messages(client, channel):
    """Ù…Ø²Ø§Ù…Ù†Ø© Ø¢Ø®Ø± SYNC_LIMIT Ø±Ø³Ø§Ù„Ø©"""
    chan_id = f"@{channel.username}" if channel.username else str(channel.id)
    limit = None if SYNC_LIMIT <= 0 else SYNC_LIMIT
    logger.info(f"\nğŸ”„ Ù…Ø²Ø§Ù…Ù†Ø© {channel.title} ({chan_id})" + (f" Ø¨Ø­Ø¯ Ø£Ù‚ØµÙ‰ {SYNC_LIMIT} Ø±Ø³Ø§Ù„Ø©" if limit else " Ø¨Ø¯ÙˆÙ† Ø­Ø¯"))

    messages = []
    async for msg in client.iter_messages(channel, limit=limit):
        if msg.text or msg.media:
            messages.append(msg)
    messages.reverse()
    logger.info(f"ğŸ“Š ØªÙ… Ø¬Ù„Ø¨ {len(messages)} Ø±Ø³Ø§Ù„Ø©")

    # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø­Ø³Ø¨ grouped_id Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ù„Ø¨ÙˆÙ…Ø§Øª
    grouped = defaultdict(list)
    for msg in messages:
        if msg.grouped_id:
            grouped[msg.grouped_id].append(msg)

    with engine.connect() as conn:
        stored = conn.execute(
            text("SELECT telegram_message_id FROM episodes WHERE telegram_channel_id = :chan"),
            {"chan": chan_id}
        ).fetchall()
    stored_set = {r[0] for r in stored}

    new = 0
    skipped = 0
    failed_parse = 0
    no_video = 0
    processed_ids = set()

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø£ÙˆÙ„Ø§Ù‹
    for group_id, group_msgs in grouped.items():
        video_msg = next((m for m in group_msgs if has_video_media(m)), None)
        if not video_msg:
            continue
        if video_msg.id in stored_set or video_msg.id in processed_ids:
            continue
        text_msg = next((m for m in group_msgs if m.text and not has_video_media(m)), None)
        content_text = text_msg.text if text_msg else video_msg.text or ""
        has_vid = True
        # Ù‚Ø¨Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ØŒ Ù†Ø­ØªØ§Ø¬ Ù„Ù…Ø¹Ø±ÙØ© Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ø§Ø³Ù… (ØªÙ‚Ø±ÙŠØ¨ÙŠ)
        # Ù„ÙƒÙ† Ø§Ù„Ø§Ø³Ù… ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ Ø¨Ø¹Ø¯ØŒ Ù„Ø°Ù„Ùƒ Ù†Ù…Ø±Ø± 0
        name, typ, season, ep = parse_content_info(content_text, chan_id, has_vid, 0)
        if not name:
            name = f"Unnamed_Group_{group_id}"
            typ = "movie"
            season = 1
            ep = 1
            logger.debug(f"Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³Ù… Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù„Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© {group_id}")
        # Ø¨Ø¹Ø¯ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³Ù…ØŒ Ù†Ø³ØªØ·ÙŠØ¹ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¹Ø¯Ø¯
        existing = get_existing_episode_count(name)
        # ÙŠÙ…ÙƒÙ† Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„ØµØ­ÙŠØ­ØŒ Ù„ÙƒÙ†Ù†Ø§ Ø³Ù†Ø³ØªØ®Ø¯Ù… Ù…Ø§ Ù„Ø¯ÙŠÙ†Ø§
        if save_to_database(name, typ, season, ep, video_msg.id, chan_id):
            new += 1
            processed_ids.add(video_msg.id)

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„ÙØ±Ø¯ÙŠØ©
    for msg in messages:
        if msg.id in processed_ids or msg.id in stored_set:
            skipped += 1
            continue

        has_vid = has_video_media(msg)
        if not has_vid:
            no_video += 1
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø³ÙŠØ§Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ ÙŠØ¨Ø¯Ùˆ ÙƒØ§Ø³Ù… Ù…Ø³Ù„Ø³Ù„ (Ø¨Ø¯ÙˆÙ† Ø£Ø±Ù‚Ø§Ù…)
            if msg.text:
                name, typ, _, _ = parse_content_info(msg.text, chan_id, False, 0)
                if name and typ == 'series' and not re.search(r'\d+', name):
                    save_channel_context(chan_id, name)
            continue

        # Ù‡Ù†Ø§ Ù„Ø¯ÙŠÙ†Ø§ ÙÙŠØ¯ÙŠÙˆØŒ Ù†Ø­ØªØ§Ø¬ Ù„Ù…Ø¹Ø±ÙØ© Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ø§Ø³Ù…
        # Ù„ÙƒÙ†Ù†Ø§ Ù„Ø§ Ù†Ø¹Ø±Ù Ø§Ù„Ø§Ø³Ù… Ø¨Ø¹Ø¯. Ø³Ù†Ø­Ù„Ù„ Ø£ÙˆÙ„Ø§Ù‹ Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø¹Ø¯Ø¯
        name, typ, season, ep = parse_content_info(msg.text or "", chan_id, has_vid, 0)
        if name:
            # Ù†Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¹Ù„ÙŠ
            existing = get_existing_episode_count(name)
            # Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„ØµØ­ÙŠØ­ (Ø§Ø®ØªÙŠØ§Ø±ÙŠØŒ Ù„ÙƒÙ†Ù†Ø§ Ø³Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†ÙˆØ¹ Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„)
            # ÙŠÙ…ÙƒÙ† ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†ÙˆØ¹ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ existing
            corrected_type = determine_content_type(name, existing)
            if corrected_type != typ:
                logger.debug(f"ØªØµØ­ÙŠØ­ Ø§Ù„Ù†ÙˆØ¹ Ù„Ù€ {name} Ù…Ù† {typ} Ø¥Ù„Ù‰ {corrected_type} Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ù„Ù‚Ø§Øª ({existing})")
                typ = corrected_type
        else:
            # ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ø³Ù… Ø§ÙØªØ±Ø§Ø¶ÙŠ
            name = f"Unnamed_{msg.id}"
            typ = "movie"
            season = 1
            ep = 1

        if save_to_database(name, typ, season, ep, msg.id, chan_id):
            new += 1
            stored_set.add(msg.id)
        else:
            with engine.connect() as conn2:
                exists = conn2.execute(
                    text("SELECT 1 FROM episodes WHERE telegram_message_id = :mid"),
                    {"mid": msg.id}
                ).scalar()
                if exists:
                    skipped += 1
                else:
                    failed_parse += 1
                    logger.error(f"âŒ ÙØ´Ù„ Ø¥Ø¯Ø±Ø§Ø¬ {msg.id} (ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ Ø§Ù„Ø³Ø¨Ø¨)")

    logger.info(f"âœ… {channel.title}: {new} Ø¬Ø¯ÙŠØ¯Ø©, {skipped} Ù…ÙˆØ¬ÙˆØ¯Ø©, {failed_parse} ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„, {no_video} Ø¨Ø¯ÙˆÙ† ÙÙŠØ¯ÙŠÙˆ")

async def import_channel_history(client, channel):
    await sync_channel_messages(client, channel)  # Ù…Ø¹ SYNC_LIMIT <= 0 Ø³ØªØ¬Ù„Ø¨ Ø§Ù„ÙƒÙ„

async def force_sync_all_messages(client, channel):
    """Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ ÙÙŠ Ø§Ù„Ù‚Ù†Ø§Ø© Ø¨ØºØ¶ Ø§Ù„Ù†Ø¸Ø± Ø¹Ù† ÙˆØ¬ÙˆØ¯Ù‡Ø§ (ÙØ­Øµ Ø¥Ø¬Ø¨Ø§Ø±ÙŠ)"""
    chan_id = f"@{channel.username}" if channel.username else str(channel.id)
    logger.info(f"\nğŸ” ÙØ­Øµ Ø¥Ø¬Ø¨Ø§Ø±ÙŠ Ù„Ù€ {channel.title} ({chan_id}) - Ø¬Ù„Ø¨ ÙƒÙ„ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„")

    all_msgs = []
    async for msg in client.iter_messages(channel, limit=None):
        if msg.text or msg.media:
            all_msgs.append(msg)
    logger.info(f"ğŸ“Š ØªÙ… Ø¬Ù„Ø¨ {len(all_msgs)} Ø±Ø³Ø§Ù„Ø©")

    with engine.connect() as conn:
        stored = conn.execute(
            text("SELECT telegram_message_id FROM episodes WHERE telegram_channel_id = :chan"),
            {"chan": chan_id}
        ).fetchall()
    stored_set = {r[0] for r in stored}

    new = 0
    for msg in all_msgs:
        if msg.id in stored_set:
            continue
        if has_video_media(msg):
            name, typ, season, ep = parse_content_info(msg.text or "", chan_id, True, 0)
            if not name:
                name = f"Unnamed_{msg.id}"
                typ = "movie"
                season = 1
                ep = 1
            if save_to_database(name, typ, season, ep, msg.id, chan_id):
                new += 1

    logger.info(f"âœ… Ø§Ù„ÙØ­Øµ Ø§Ù„Ø¥Ø¬Ø¨Ø§Ø±ÙŠ Ù„Ù€ {channel.title}: ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© {new} Ø­Ù„Ù‚Ø© Ø¬Ø¯ÙŠØ¯Ø©")

async def check_deleted_messages(client, channel):
    chan_id = f"@{channel.username}" if channel.username else str(channel.id)
    logger.info(f"\nğŸ” ÙØ­Øµ Ø§Ù„Ù…Ø­Ø°ÙˆÙØ§Øª ÙÙŠ {channel.title}")
    try:
        with engine.connect() as conn:
            stored = conn.execute(
                text("SELECT telegram_message_id FROM episodes WHERE telegram_channel_id = :chan"),
                {"chan": chan_id}
            ).fetchall()
        stored_ids = [r[0] for r in stored]
        if not stored_ids:
            return
        current_ids = []
        async for msg in client.iter_messages(channel, limit=1000):
            current_ids.append(msg.id)
        deleted = [sid for sid in stored_ids if sid not in current_ids]
        if deleted:
            logger.info(f"ğŸ—‘ï¸ {len(deleted)} Ø±Ø³Ø§Ù„Ø© Ù…Ø­Ø°ÙˆÙØ©")
            for mid in deleted:
                delete_from_database(mid)
        else:
            logger.info("âœ… Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø­Ø°ÙˆÙØ§Øª")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙØ­Øµ: {e}")

# ------------------------------
# Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# ------------------------------
async def monitor_channels():
    logger.info(f"Ù…Ø±Ø§Ù‚Ø¨Ø© {len(CHANNEL_LIST)} Ù‚Ù†Ø§Ø©")
    client = TelegramClient(StringSession(STRING_SESSION), API_ID, API_HASH)
    await client.start()
    logger.info("âœ… Ù…ØªØµÙ„ Ø¨Ù€ Telegram")

    channels = []
    for inp in CHANNEL_LIST:
        ch = await get_channel_entity(client, inp)
        if ch:
            channels.append(ch)
            logger.info(f"âœ… {ch.title}")
    if not channels:
        logger.error("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚Ù†ÙˆØ§Øª ØµØ§Ù„Ø­Ø©")
        return

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚
    global series_context
    series_context = load_channel_context()

    # Ù…Ø²Ø§Ù…Ù†Ø© Ø£ÙˆÙ„ÙŠØ©
    for ch in channels:
        await sync_channel_messages(client, ch)

    # Ø§Ø³ØªÙŠØ±Ø§Ø¯ ÙƒØ§Ù…Ù„ Ø¥Ø°Ø§ Ù…ÙØ¹Ù„
    if IMPORT_HISTORY and SYNC_LIMIT > 0:
        for ch in channels:
            await import_channel_history(client, ch)

    # ÙØ­Øµ Ø¥Ø¬Ø¨Ø§Ø±ÙŠ Ø¥Ø°Ø§ Ù…ÙØ¹Ù„
    if os.environ.get("FORCE_SYNC", "false").lower() == "true":
        for ch in channels:
            await force_sync_all_messages(client, ch)

    clean_orphan_series()
    fix_misclassified_series()

    if CHECK_DELETED_MESSAGES:
        for ch in channels:
            await check_deleted_messages(client, ch)

    @client.on(events.NewMessage(chats=channels))
    async def handler(event):
        msg = event.message
        if msg.text or msg.media:
            chan_id = f"@{msg.chat.username}" if msg.chat.username else str(msg.chat.id)
            has_vid = has_video_media(msg)
            if has_vid:
                # Ù†Ø­ØªØ§Ø¬ Ù„Ù…Ø¹Ø±ÙØ© Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ø§Ø³Ù… Ù‚Ø¨Ù„ Ø§Ù„ØªØ®Ø²ÙŠÙ†
                # Ø³Ù†Ø­Ù„Ù„ Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø¹Ø¯Ø¯ Ø£ÙˆÙ„Ø§Ù‹
                name, typ, season, ep = parse_content_info(msg.text or "", chan_id, has_vid, 0)
                if name:
                    existing = get_existing_episode_count(name)
                    corrected_type = determine_content_type(name, existing)
                    if corrected_type != typ:
                        typ = corrected_type
                else:
                    name = f"Unnamed_{msg.id}"
                    typ = "movie"
                    season = 1
                    ep = 1
                save_to_database(name, typ, season, ep, msg.id, chan_id)
            else:
                # Ø±Ø³Ø§Ù„Ø© Ù†ØµÙŠØ© Ø¨Ø¯ÙˆÙ† ÙÙŠØ¯ÙŠÙˆØŒ Ù‚Ø¯ ØªÙƒÙˆÙ† Ø³ÙŠØ§Ù‚
                if msg.text:
                    name, typ, _, _ = parse_content_info(msg.text, chan_id, False, 0)
                    if name and typ == 'series' and not re.search(r'\d+', name):
                        save_channel_context(chan_id, name)
                        series_context[chan_id] = name

    @client.on(events.MessageDeleted(chats=channels))
    async def delete_handler(event):
        for mid in event.deleted_ids:
            delete_from_database(mid)

    logger.info("ğŸ¯ ÙÙŠ Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ø£Ø­Ø¯Ø§Ø«...")
    await client.run_until_disconnected()

if __name__ == "__main__":
    asyncio.run(monitor_channels())
