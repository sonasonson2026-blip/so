import os
import asyncio
import re
import sys
import logging
import unicodedata
from collections import defaultdict
from datetime import datetime
from telethon import TelegramClient, events, types
from telethon.sessions import StringSession
from telethon.tl.functions.messages import ImportChatInviteRequest
from sqlalchemy import create_engine, text
from sqlalchemy.exc import SQLAlchemyError

# ------------------------------
# Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
# ------------------------------
API_ID = int(os.environ.get("API_ID", 0))
API_HASH = os.environ.get("API_HASH", "")
CHANNELS = os.environ.get("CHANNELS", "https://t.me/ShoofFilm,https://t.me/shoofcima")
DATABASE_URL = os.environ.get("DATABASE_URL", "")
STRING_SESSION = os.environ.get("STRING_SESSION", "")
IMPORT_HISTORY = os.environ.get("IMPORT_HISTORY", "false").lower() == "true"
CHECK_DELETED_MESSAGES = os.environ.get("CHECK_DELETED_MESSAGES", "true").lower() == "true"
DEBUG_MODE = os.environ.get("DEBUG_MODE", "false").lower() == "true"
RESET_DATABASE = os.environ.get("RESET_DATABASE", "false").lower() == "true"
SYNC_LIMIT = int(os.environ.get("SYNC_LIMIT", "10000"))  # Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ù„Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© (0 = ØºÙŠØ± Ù…Ø­Ø¯ÙˆØ¯)

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.DEBUG if DEBUG_MODE else logging.INFO
)
logger = logging.getLogger(__name__)

if not all([API_ID, API_HASH, DATABASE_URL, STRING_SESSION]):
    logger.error("âŒ Ù…ØªØºÙŠØ±Ø§Øª Ù…ÙÙ‚ÙˆØ¯Ø©")
    sys.exit(1)

if DATABASE_URL.startswith("postgres://"):
    DATABASE_URL = DATABASE_URL.replace("postgres://", "postgresql://", 1)

CHANNEL_LIST = [chan.strip() for chan in CHANNELS.split(',') if chan.strip()]

# ------------------------------
# Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¹ÙŠÙŠÙ† Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
# ------------------------------
try:
    engine = create_engine(DATABASE_URL)
    with engine.connect() as conn:
        conn.execute(text("SELECT 1"))
    logger.info("âœ… Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    
    if RESET_DATABASE:
        logger.warning("âš ï¸ Ø¬Ø§Ø±ÙŠ Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
        with engine.begin() as conn:
            conn.execute(text("DROP SCHEMA public CASCADE"))
            conn.execute(text("CREATE SCHEMA public"))
        logger.info("âœ… ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
except Exception as e:
    logger.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
    sys.exit(1)

# ------------------------------
# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
# ------------------------------
with engine.begin() as conn:
    conn.execute(text("""
        CREATE TABLE IF NOT EXISTS series (
            id SERIAL PRIMARY KEY,
            name VARCHAR(255) NOT NULL,
            type VARCHAR(10) DEFAULT 'series',
            normalized_name VARCHAR(255),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """))
    conn.execute(text("""
        CREATE TABLE IF NOT EXISTS episodes (
            id SERIAL PRIMARY KEY,
            series_id INTEGER REFERENCES series(id),
            season INTEGER DEFAULT 1,
            episode_number INTEGER NOT NULL,
            telegram_message_id INTEGER UNIQUE NOT NULL,
            telegram_channel_id VARCHAR(255),
            added_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """))
    conn.execute(text("""
        CREATE TABLE IF NOT EXISTS channel_context (
            channel_id VARCHAR(255) PRIMARY KEY,
            series_name VARCHAR(255) NOT NULL,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """))
    conn.execute(text("CREATE INDEX IF NOT EXISTS idx_series_normalized_name ON series(normalized_name)"))
    conn.execute(text("CREATE UNIQUE INDEX IF NOT EXISTS idx_episodes_msg_id ON episodes(telegram_message_id)"))
    conn.execute(text("CREATE INDEX IF NOT EXISTS idx_episodes_channel_id ON episodes(telegram_channel_id)"))
    conn.execute(text("CREATE INDEX IF NOT EXISTS idx_episodes_added_at ON episodes(added_at)"))
logger.info("âœ… Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø¬Ø§Ù‡Ø²Ø©")

# ------------------------------
# Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ ÙˆØ§Ù„ØªØ·Ø¨ÙŠØ¹
# ------------------------------
def normalize_arabic(text):
    if not text:
        return ''
    text = unicodedata.normalize('NFKD', text)
    text = re.sub(r'[\u064B-\u065F]', '', text)
    text = text.replace('Ø¥', 'Ø§').replace('Ø£', 'Ø§').replace('Ø¢', 'Ø§').replace('Ù‰', 'Ø§')
    text = text.replace('Ø©', 'Ù‡')
    return text

def normalize_series_name(name):
    if not name:
        return ''
    name = re.sub(r'^(Ù…Ø³Ù„Ø³Ù„|ÙÙŠÙ„Ù…)\s+', '', name, flags=re.UNICODE)
    name = re.sub(r'\s+(Ø§Ù„Ø­Ù„Ù‚Ø©|Ø§Ù„Ù…ÙˆØ³Ù…|Ø§Ù„Ø¬Ø²Ø¡)$', '', name, flags=re.UNICODE)
    name = re.sub(r'\s+\d+$', '', name)
    name = normalize_arabic(name)
    name = re.sub(r'\s+', ' ', name).strip().lower()
    return name

def clean_name_for_series(name):
    name = re.sub(r'^Ù…Ø³Ù„Ø³Ù„\s+', '', name, flags=re.UNICODE)
    name = re.sub(r'\s+(Ø§Ù„Ø­Ù„Ù‚Ø©|Ø§Ù„Ù…ÙˆØ³Ù…)$', '', name, flags=re.UNICODE)
    name = re.sub(r'\s+\d+$', '', name)
    name = re.sub(r'\s+', ' ', name).strip()
    return name

def clean_name_for_movie(name):
    name = re.sub(r'^ÙÙŠÙ„Ù…\s+', '', name, flags=re.UNICODE)
    name = re.sub(r'\s+Ø§Ù„Ø¬Ø²Ø¡\s*\d*$', '', name, flags=re.UNICODE)
    name = re.sub(r'\s+\d+$', '', name)
    name = re.sub(r'\s+', ' ', name).strip()
    return name

# ------------------------------
# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„Ø³ÙŠØ§Ù‚
# ------------------------------
def load_channel_context():
    context = {}
    try:
        with engine.connect() as conn:
            rows = conn.execute(text("SELECT channel_id, series_name FROM channel_context")).fetchall()
            for row in rows:
                context[row[0]] = row[1]
        logger.info(f"ğŸ“‚ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø³ÙŠØ§Ù‚ {len(context)} Ù‚Ù†Ø§Ø© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    except Exception as e:
        logger.error(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚: {e}")
    return context

def save_channel_context(channel_id, series_name):
    try:
        with engine.begin() as conn:
            conn.execute(
                text("""
                    INSERT INTO channel_context (channel_id, series_name)
                    VALUES (:chan, :name)
                    ON CONFLICT (channel_id) DO UPDATE SET series_name = :name, updated_at = CURRENT_TIMESTAMP
                """),
                {"chan": channel_id, "name": series_name}
            )
        logger.debug(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø³ÙŠØ§Ù‚ Ù„Ù„Ù‚Ù†Ø§Ø© {channel_id}: {series_name}")
    except Exception as e:
        logger.error(f"âŒ ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ø³ÙŠØ§Ù‚: {e}")

# ------------------------------
# Ø¯Ø§Ù„Ø© Ù…Ø­Ø³Ù†Ø© Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
# ------------------------------
def has_video_media(msg):
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø±Ø³Ø§Ù„Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙÙŠØ¯ÙŠÙˆ Ø­Ù‚ÙŠÙ‚ÙŠ"""
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ ÙÙŠØ¯ÙŠÙˆ Ù…Ø¨Ø§Ø´Ø±Ø©
    if msg.video:
        return True
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ø³ØªÙ†Ø¯ Ù‚Ø¯ ÙŠÙƒÙˆÙ† ÙÙŠØ¯ÙŠÙˆ
    if msg.document:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† mime_type
        mime = msg.document.mime_type or ''
        if mime.startswith('video/'):
            return True
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ù…ØªØ¯Ø§Ø¯ Ø¥Ø°Ø§ ÙƒØ§Ù† mime_type ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ
        if msg.document.attributes:
            for attr in msg.document.attributes:
                if isinstance(attr, types.DocumentAttributeFilename):
                    ext = os.path.splitext(attr.file_name)[-1].lower()
                    if ext in ['.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.webm', '.m4v', '.3gp']:
                        return True
                elif isinstance(attr, types.DocumentAttributeVideo):
                    return True
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ø¬Ù… (Ù‚Ø¯ ÙŠÙƒÙˆÙ† ÙÙŠØ¯ÙŠÙˆ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø£ÙƒØ¨Ø± Ù…Ù† 1 Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª ÙˆÙƒØ§Ù† mime ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ)
        if msg.document.size > 1024 * 1024 and 'octet-stream' in mime:
            return True
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ media (Ù„Ù„ØªØ£ÙƒØ¯)
    if msg.media and hasattr(msg.media, 'document'):
        # ØªÙƒØ±Ø§Ø± Ù†ÙØ³ Ø§Ù„ÙØ­Øµ
        doc = msg.media.document
        mime = doc.mime_type or ''
        if mime.startswith('video/'):
            return True
        for attr in doc.attributes:
            if isinstance(attr, types.DocumentAttributeFilename):
                ext = os.path.splitext(attr.file_name)[-1].lower()
                if ext in ['.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.webm', '.m4v', '.3gp']:
                    return True
            elif isinstance(attr, types.DocumentAttributeVideo):
                return True
        if doc.size > 1024 * 1024 and 'octet-stream' in mime:
            return True
    return False

# ------------------------------
# Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­Ø³Ù†Ø© Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
# ------------------------------
def parse_content_info(msg_text, channel_id, has_video):
    """
    ØªØ­Ù„ÙŠÙ„ Ù†Øµ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆÙ†ÙˆØ¹Ù‡ (Ù…Ø³Ù„Ø³Ù„/ÙÙŠÙ„Ù…) ÙˆØ±Ù‚Ù… Ø§Ù„Ù…ÙˆØ³Ù… ÙˆØ§Ù„Ø­Ù„Ù‚Ø©.
    ØªØ¹ÙŠØ¯ (name, type, season, episode) Ø£Ùˆ (None, None, None, None) Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ ÙÙŠØ¯ÙŠÙˆ.
    """
    if not msg_text or not has_video:
        return None, None, None, None

    original_text = msg_text.strip()
    text = original_text

    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
    common_prefixes = ['Ù…Ø´Ø§Ù‡Ø¯Ø©', 'ØªØ­Ù…ÙŠÙ„', 'Ø§Ù„Ø¢Ù†', 'Ù…Ø³Ù„Ø³Ù„', 'ÙÙŠÙ„Ù…', 'Ø´Ø§Ù‡Ø¯', 'Ù…ØªØ±Ø¬Ù…', 'Ø­Ù„Ù‚Ø©', 'Ø§Ù„Ù…Ø³Ù„Ø³Ù„', 'Ù…Ø´Ø§Ù‡Ø¯Ù‡']
    for prefix in common_prefixes:
        if text.startswith(prefix):
            text = text[len(prefix):].strip()
            text = re.sub(r'^[\s:-]+', '', text)

    lower_text = text.lower()

    season = 1
    episode = 1
    name = text
    content_type = 'movie'  # Ø§ÙØªØ±Ø§Ø¶ÙŠ

    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ù†Ù…Ø§Ø·
    patterns = [
        # S01E05, s1e5
        (r'^(.*?)\s*[Ss](\d+)[Ee](\d+)$', lambda m: (m.group(1).strip(), int(m.group(2)), int(m.group(3)))),
        (r'^(.*?)\s*[Ss](\d+)[Ee](\d+)', lambda m: (m.group(1).strip(), int(m.group(2)), int(m.group(3)))),
        # Ø§Ù„Ù…ÙˆØ³Ù… X Ø§Ù„Ø­Ù„Ù‚Ø© Y
        (r'(.*?)\s*Ø§Ù„Ù…ÙˆØ³Ù…\s*[:_-]?\s*(\d+)\s*Ø§Ù„Ø­Ù„Ù‚Ø©\s*[:_-]?\s*(\d+)', lambda m: (m.group(1).strip(), int(m.group(2)), int(m.group(3)))),
        (r'(.*?)\s*Ø§Ù„Ø­Ù„Ù‚Ø©\s*[:_-]?\s*(\d+)\s*Ù…Ù†\s*Ø§Ù„Ù…ÙˆØ³Ù…\s*[:_-]?\s*(\d+)', lambda m: (m.group(1).strip(), int(m.group(3)), int(m.group(2)))),
        (r'(.*?)\s*Ø§Ù„Ù…ÙˆØ³Ù…\s*[:_-]?\s*(\d+)\s*-\s*(\d+)', lambda m: (m.group(1).strip(), int(m.group(2)), int(m.group(3)))),
        (r'(.*?)\s*Ù…(\d+)\s*Ø­(\d+)', lambda m: (m.group(1).strip(), int(m.group(2)), int(m.group(3)))),
        # Ø§Ù„Ø­Ù„Ù‚Ø© X
        (r'(.*?)\s*Ø§Ù„Ø­Ù„Ù‚Ø©\s*[:_-]?\s*(\d+)', lambda m: (m.group(1).strip(), 1, int(m.group(2)))),
        # Ø§Ø³Ù… + Ø±Ù‚Ù…ÙŠÙ† ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©
        (r'^(.*?)\s+(\d+)[-\s]+(\d+)$', lambda m: (m.group(1).strip(), int(m.group(2)), int(m.group(3)))),
        (r'^(.*?)\s+(\d+)[-\s]*(\d+)$', lambda m: (m.group(1).strip(), int(m.group(2)), int(m.group(3)))),
        # Ø±Ù‚Ù… ÙˆØ§Ø­Ø¯ ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©
        (r'^(.*?)\s+(\d+)$', lambda m: (m.group(1).strip(), 1, int(m.group(2)))),
        # Ø§Ù„Ø¬Ø²Ø¡ X
        (r'(.*?)\s*Ø§Ù„Ø¬Ø²Ø¡\s*[:_-]?\s*(\d+)', lambda m: (m.group(1).strip(), int(m.group(2)), 1)),
    ]

    for pattern, extractor in patterns:
        match = re.search(pattern, text, re.UNICODE)
        if match:
            try:
                name, season, episode = extractor(match)
                content_type = 'series'
                break
            except:
                continue

    # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù†Ù…Ø·
    if content_type == 'movie':
        if 'ÙÙŠÙ„Ù…' in lower_text:
            content_type = 'movie'
            name = re.sub(r'ÙÙŠÙ„Ù…\s*', '', text, flags=re.UNICODE).strip()
            part_match = re.search(r'Ø§Ù„Ø¬Ø²Ø¡\s*[:_-]?\s*(\d+)', text, re.UNICODE)
            if part_match:
                season = int(part_match.group(1))
                episode = 1
                name = re.sub(r'Ø§Ù„Ø¬Ø²Ø¡\s*\d+', '', name, flags=re.UNICODE).strip()
        else:
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ÙÙŠØ¯ÙŠÙˆ ÙˆÙ„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Øµ ÙƒØ§Ù…Ù„Ø§Ù‹ ÙƒÙÙŠÙ„Ù… (Ø§Ø­ØªÙŠØ§Ø·ÙŠ)
            content_type = 'movie'
            name = original_text

    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø§Ø³Ù…
    name = re.sub(r'\s+', ' ', name).strip()
    name = re.sub(r'\s+\d+$', '', name)  # Ø¥Ø²Ø§Ù„Ø© Ø£Ø±Ù‚Ø§Ù… Ø²Ø§Ø¦Ø¯Ø©

    if not name:
        name = original_text[:200]

    logger.debug(f"ØªÙ… ØªØ­Ù„ÙŠÙ„: '{original_text[:50]}...' -> {name}, {content_type}, S{season}E{episode}")
    return name, content_type, season, episode

# ------------------------------
# Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù‚Ù†ÙˆØ§Øª
# ------------------------------
async def get_channel_entity(client, channel_input):
    try:
        return await client.get_entity(channel_input)
    except Exception as e:
        logger.warning(f"âš ï¸ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ÙˆØµÙˆÙ„ {channel_input}: {e}")
        if isinstance(channel_input, str) and channel_input.startswith('https://t.me/+'):
            try:
                invite = channel_input.split('+')[-1]
                await client(ImportChatInviteRequest(invite))
                return await client.get_entity(channel_input)
            except:
                return None
        return None

def save_to_database(name, content_type, season, episode, msg_id, channel_id):
    try:
        with engine.begin() as conn:
            normalized = normalize_series_name(name)
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø³Ù„Ø³Ù„
            row = conn.execute(
                text("SELECT id FROM series WHERE normalized_name = :norm AND type = :typ"),
                {"norm": normalized, "typ": content_type}
            ).fetchone()
            if not row:
                words = name.split()[:3]
                if words:
                    like = '%' + '%'.join(words) + '%'
                    row = conn.execute(
                        text("SELECT id FROM series WHERE name ILIKE :pat AND type = :typ LIMIT 1"),
                        {"pat": like, "typ": content_type}
                    ).fetchone()
            if not row:
                row = conn.execute(
                    text("INSERT INTO series (name, normalized_name, type) VALUES (:name, :norm, :typ) RETURNING id"),
                    {"name": name, "norm": normalized, "typ": content_type}
                ).fetchone()
            sid = row[0]

            inserted = conn.execute(
                text("""
                    INSERT INTO episodes (series_id, season, episode_number, telegram_message_id, telegram_channel_id)
                    VALUES (:sid, :season, :ep, :msg, :chan)
                    ON CONFLICT (telegram_message_id) DO NOTHING
                    RETURNING id
                """),
                {"sid": sid, "season": season, "ep": episode, "msg": msg_id, "chan": channel_id}
            ).fetchone()
            if inserted:
                logger.info(f"âœ… Ø¬Ø¯ÙŠØ¯: {name} - Ù…{season} Ø­{episode} Ù…Ù† {channel_id}")
                return True
            else:
                logger.debug(f"âš ï¸ Ù…ÙˆØ¬ÙˆØ¯Ø©: {msg_id}")
                return False
    except Exception as e:
        logger.exception(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ÙØ¸ Ù„Ù„Ø±Ø³Ø§Ù„Ø© {msg_id}: {e}")
        return False

def delete_from_database(msg_id):
    try:
        with engine.begin() as conn:
            ep = conn.execute(
                text("SELECT series_id FROM episodes WHERE telegram_message_id = :msg"),
                {"msg": msg_id}
            ).fetchone()
            if not ep:
                return False
            sid = ep[0]
            conn.execute(text("DELETE FROM episodes WHERE telegram_message_id = :msg"), {"msg": msg_id})
            remaining = conn.execute(
                text("SELECT COUNT(*) FROM episodes WHERE series_id = :sid"),
                {"sid": sid}
            ).scalar()
            if remaining == 0:
                conn.execute(text("DELETE FROM series WHERE id = :sid"), {"sid": sid})
                logger.info(f"ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ø³Ù„Ø³Ù„ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ (Ø¢Ø®Ø± Ø­Ù„Ù‚Ø© {msg_id})")
            else:
                logger.info(f"ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ø­Ù„Ù‚Ø© {msg_id}")
            return True
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­Ø°Ù: {e}")
        return False

def clean_orphan_series():
    try:
        with engine.begin() as conn:
            result = conn.execute(text("""
                DELETE FROM series
                WHERE id NOT IN (SELECT DISTINCT series_id FROM episodes)
                RETURNING id, name, type
            """)).fetchall()
            if result:
                for r in result:
                    logger.info(f"ğŸ§¹ ØªÙ… Ø­Ø°Ù {r[2]} Ø¨Ø¯ÙˆÙ† Ø­Ù„Ù‚Ø§Øª: {r[1]} (ID: {r[0]})")
                logger.info(f"âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ {len(result)} Ù…Ø³Ù„Ø³Ù„/ÙÙŠÙ„Ù… Ø¨Ø¯ÙˆÙ† Ø­Ù„Ù‚Ø§Øª")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„ÙŠØªÙŠÙ…Ø©: {e}")

def fix_misclassified_series():
    try:
        with engine.begin() as conn:
            rows = conn.execute(text("""
                SELECT s.id, s.name, COUNT(e.id) as ep_count
                FROM series s
                JOIN episodes e ON s.id = e.series_id
                WHERE s.type = 'movie'
                GROUP BY s.id, s.name
                HAVING COUNT(e.id) > 1
            """)).fetchall()
            if rows:
                for row in rows:
                    sid, name, count = row
                    conn.execute(
                        text("UPDATE series SET type = 'series' WHERE id = :sid"),
                        {"sid": sid}
                    )
                    logger.info(f"ğŸ”„ ØªÙ… ØªØµØ­ÙŠØ­ {name} (ID: {sid}) Ù…Ù† ÙÙŠÙ„Ù… Ø¥Ù„Ù‰ Ù…Ø³Ù„Ø³Ù„ (Ù„Ø¯ÙŠÙ‡ {count} Ø­Ù„Ù‚Ø§Øª)")
                logger.info(f"âœ… ØªÙ… ØªØµØ­ÙŠØ­ {len(rows)} Ù…Ø³Ù„Ø³Ù„ ÙƒØ§Ù† Ù…ØµÙ†Ù Ø®Ø·Ø£ ÙƒÙÙŠÙ„Ù…")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØµØ­ÙŠØ­ Ø§Ù„ØªØµÙ†ÙŠÙ: {e}")

# ------------------------------
# Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù‚Ù†ÙˆØ§Øª
# ------------------------------
async def sync_channel_messages(client, channel):
    chan_id = f"@{channel.username}" if channel.username else str(channel.id)
    limit = None if SYNC_LIMIT <= 0 else SYNC_LIMIT
    logger.info(f"\nğŸ”„ Ù…Ø²Ø§Ù…Ù†Ø© {channel.title} ({chan_id})" + (f" Ø¨Ø­Ø¯ Ø£Ù‚ØµÙ‰ {SYNC_LIMIT} Ø±Ø³Ø§Ù„Ø©" if limit else " Ø¨Ø¯ÙˆÙ† Ø­Ø¯"))

    messages = []
    async for msg in client.iter_messages(channel, limit=limit):
        if msg.text:
            messages.append(msg)
    messages.reverse()
    logger.info(f"ğŸ“Š ØªÙ… Ø¬Ù„Ø¨ {len(messages)} Ø±Ø³Ø§Ù„Ø© Ù†ØµÙŠØ©" + (f" (Ø¢Ø®Ø± {SYNC_LIMIT})" if limit else " (ÙƒØ§Ù…Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ®)"))

    with engine.connect() as conn:
        stored = conn.execute(
            text("SELECT telegram_message_id FROM episodes WHERE telegram_channel_id = :chan"),
            {"chan": chan_id}
        ).fetchall()
    stored_set = {r[0] for r in stored}

    new = 0
    skipped = 0
    failed_parse = 0
    no_video = 0

    for msg in messages:
        if msg.id in stored_set:
            skipped += 1
            continue

        has_video = has_video_media(msg)
        if not has_video:
            no_video += 1
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø³ÙŠØ§Ù‚ Ø¥Ø°Ø§ Ø£Ù…ÙƒÙ†
            name, typ, season, ep = parse_content_info(msg.text, chan_id, has_video)
            if name and not has_video and typ == 'series' and not re.search(r'\d+', name):
                save_channel_context(chan_id, name)
            continue

        name, typ, season, ep = parse_content_info(msg.text, chan_id, has_video)

        if name and typ and ep:
            if save_to_database(name, typ, season, ep, msg.id, chan_id):
                new += 1
                stored_set.add(msg.id)
            else:
                with engine.connect() as conn2:
                    exists = conn2.execute(
                        text("SELECT 1 FROM episodes WHERE telegram_message_id = :mid"),
                        {"mid": msg.id}
                    ).scalar()
                    if exists:
                        skipped += 1
                    else:
                        failed_parse += 1
                        logger.error(f"âŒ ÙØ´Ù„ Ø¥Ø¯Ø±Ø§Ø¬ {msg.id} (ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ Ø§Ù„Ø³Ø¨Ø¨)")
        else:
            failed_parse += 1
            logger.debug(f"âš ï¸ ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© {msg.id}: {msg.text[:50]}...")

    logger.info(f"âœ… {channel.title}: {new} Ø¬Ø¯ÙŠØ¯Ø©, {skipped} Ù…ÙˆØ¬ÙˆØ¯Ø©, {failed_parse} ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„, {no_video} Ø¨Ø¯ÙˆÙ† ÙÙŠØ¯ÙŠÙˆ")

async def import_channel_history(client, channel):
    """Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© (Ø¨Ø¯ÙˆÙ† Ø­Ø¯)"""
    chan_id = f"@{channel.username}" if channel.username else str(channel.id)
    logger.info(f"\nğŸ“‚ Ø§Ø³ØªÙŠØ±Ø§Ø¯ ÙƒØ§Ù…Ù„ {channel.title}")

    all_msgs = []
    async for msg in client.iter_messages(channel, limit=None):
        if msg.text:
            all_msgs.append(msg)
    all_msgs.reverse()
    logger.info(f"ğŸ“Š ØªÙ… Ø¬Ù„Ø¨ {len(all_msgs)} Ø±Ø³Ø§Ù„Ø© Ù†ØµÙŠØ© (ÙƒØ§Ù…Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ®)")

    with engine.connect() as conn:
        stored = conn.execute(
            text("SELECT telegram_message_id FROM episodes WHERE telegram_channel_id = :chan"),
            {"chan": chan_id}
        ).fetchall()
    stored_set = {r[0] for r in stored}

    new = 0
    skipped = 0
    failed_parse = 0
    no_video = 0

    for msg in all_msgs:
        if msg.id in stored_set:
            skipped += 1
            continue

        has_video = has_video_media(msg)
        if not has_video:
            no_video += 1
            name, typ, season, ep = parse_content_info(msg.text, chan_id, has_video)
            if name and not has_video and typ == 'series' and not re.search(r'\d+', name):
                save_channel_context(chan_id, name)
            continue

        name, typ, season, ep = parse_content_info(msg.text, chan_id, has_video)

        if name and typ and ep:
            if save_to_database(name, typ, season, ep, msg.id, chan_id):
                new += 1
                stored_set.add(msg.id)
            else:
                with engine.connect() as conn2:
                    exists = conn2.execute(
                        text("SELECT 1 FROM episodes WHERE telegram_message_id = :mid"),
                        {"mid": msg.id}
                    ).scalar()
                    if exists:
                        skipped += 1
                    else:
                        failed_parse += 1
                        logger.error(f"âŒ ÙØ´Ù„ Ø¥Ø¯Ø±Ø§Ø¬ {msg.id} (ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ Ø§Ù„Ø³Ø¨Ø¨)")
        else:
            failed_parse += 1
            logger.debug(f"âš ï¸ ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© {msg.id}: {msg.text[:50]}...")

    logger.info(f"ğŸ“¥ {channel.title}: {new} Ø¬Ø¯ÙŠØ¯Ø©, {skipped} Ù…ÙˆØ¬ÙˆØ¯Ø©, {failed_parse} ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„, {no_video} Ø¨Ø¯ÙˆÙ† ÙÙŠØ¯ÙŠÙˆ")

async def check_deleted_messages(client, channel):
    chan_id = f"@{channel.username}" if channel.username else str(channel.id)
    logger.info(f"\nğŸ” ÙØ­Øµ Ø§Ù„Ù…Ø­Ø°ÙˆÙØ§Øª ÙÙŠ {channel.title}")
    try:
        with engine.connect() as conn:
            stored = conn.execute(
                text("SELECT telegram_message_id FROM episodes WHERE telegram_channel_id = :chan"),
                {"chan": chan_id}
            ).fetchall()
        stored_ids = [r[0] for r in stored]
        if not stored_ids:
            return
        current_ids = []
        async for msg in client.iter_messages(channel, limit=1000):
            current_ids.append(msg.id)
        deleted = [sid for sid in stored_ids if sid not in current_ids]
        if deleted:
            logger.info(f"ğŸ—‘ï¸ {len(deleted)} Ø±Ø³Ø§Ù„Ø© Ù…Ø­Ø°ÙˆÙØ©")
            for mid in deleted:
                delete_from_database(mid)
        else:
            logger.info("âœ… Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø­Ø°ÙˆÙØ§Øª")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙØ­Øµ: {e}")

# ------------------------------
# Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# ------------------------------
async def monitor_channels():
    logger.info(f"Ù…Ø±Ø§Ù‚Ø¨Ø© {len(CHANNEL_LIST)} Ù‚Ù†Ø§Ø©")
    client = TelegramClient(StringSession(STRING_SESSION), API_ID, API_HASH)
    await client.start()
    logger.info("âœ… Ù…ØªØµÙ„ Ø¨Ù€ Telegram")

    channels = []
    for inp in CHANNEL_LIST:
        ch = await get_channel_entity(client, inp)
        if ch:
            channels.append(ch)
            logger.info(f"âœ… {ch.title}")
    if not channels:
        logger.error("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚Ù†ÙˆØ§Øª ØµØ§Ù„Ø­Ø©")
        return

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚
    global series_context
    series_context = load_channel_context()

    # Ù…Ø²Ø§Ù…Ù†Ø© Ø£ÙˆÙ„ÙŠØ©
    for ch in channels:
        await sync_channel_messages(client, ch)

    # Ø§Ø³ØªÙŠØ±Ø§Ø¯ ÙƒØ§Ù…Ù„ Ø¥Ø°Ø§ Ù…ÙØ¹Ù„
    if IMPORT_HISTORY:
        for ch in channels:
            await import_channel_history(client, ch)

    clean_orphan_series()
    fix_misclassified_series()

    if CHECK_DELETED_MESSAGES:
        for ch in channels:
            await check_deleted_messages(client, ch)

    @client.on(events.NewMessage(chats=channels))
    async def handler(event):
        msg = event.message
        if msg.text:
            chan_id = f"@{msg.chat.username}" if msg.chat.username else str(msg.chat.id)
            has_video = has_video_media(msg)
            name, typ, season, ep = parse_content_info(msg.text, chan_id, has_video)
            if has_video and name and typ and ep:
                save_to_database(name, typ, season, ep, msg.id, chan_id)
            elif name and not has_video and typ == 'series' and not re.search(r'\d+', name):
                save_channel_context(chan_id, name)
                series_context[chan_id] = name

    @client.on(events.MessageDeleted(chats=channels))
    async def delete_handler(event):
        for mid in event.deleted_ids:
            delete_from_database(mid)

    logger.info("ğŸ¯ ÙÙŠ Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ø£Ø­Ø¯Ø§Ø«...")
    await client.run_until_disconnected()

if __name__ == "__main__":
    asyncio.run(monitor_channels())
