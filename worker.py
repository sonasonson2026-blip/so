import os
import asyncio
import re
import sys
import logging
import unicodedata
from collections import defaultdict
from datetime import datetime
from telethon import TelegramClient, events
from telethon.sessions import StringSession
from telethon.tl.functions.messages import ImportChatInviteRequest
from sqlalchemy import create_engine, text
from sqlalchemy.exc import SQLAlchemyError

# ------------------------------
# Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
# ------------------------------
API_ID = int(os.environ.get("API_ID", 0))
API_HASH = os.environ.get("API_HASH", "")
CHANNELS = os.environ.get("CHANNELS", "https://t.me/ShoofFilm,https://t.me/shoofcima")
DATABASE_URL = os.environ.get("DATABASE_URL", "")
STRING_SESSION = os.environ.get("STRING_SESSION", "")
IMPORT_HISTORY = os.environ.get("IMPORT_HISTORY", "false").lower() == "true"
CHECK_DELETED_MESSAGES = os.environ.get("CHECK_DELETED_MESSAGES", "true").lower() == "true"
DEBUG_MODE = os.environ.get("DEBUG_MODE", "false").lower() == "true"

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.DEBUG if DEBUG_MODE else logging.INFO
)
logger = logging.getLogger(__name__)

if not all([API_ID, API_HASH, DATABASE_URL, STRING_SESSION]):
    logger.error("âŒ Ù…ØªØºÙŠØ±Ø§Øª Ù…ÙÙ‚ÙˆØ¯Ø©")
    sys.exit(1)

if DATABASE_URL.startswith("postgres://"):
    DATABASE_URL = DATABASE_URL.replace("postgres://", "postgresql://", 1)

CHANNEL_LIST = [chan.strip() for chan in CHANNELS.split(',') if chan.strip()]

# ------------------------------
# Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ------------------------------
try:
    engine = create_engine(DATABASE_URL)
    with engine.connect() as conn:
        conn.execute(text("SELECT 1"))
    logger.info("âœ… Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
except Exception as e:
    logger.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
    sys.exit(1)

# ------------------------------
# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
# ------------------------------
with engine.begin() as conn:
    conn.execute(text("""
        CREATE TABLE IF NOT EXISTS series (
            id SERIAL PRIMARY KEY,
            name VARCHAR(255) NOT NULL,
            type VARCHAR(10) DEFAULT 'series',
            normalized_name VARCHAR(255),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """))
    conn.execute(text("""
        CREATE TABLE IF NOT EXISTS episodes (
            id SERIAL PRIMARY KEY,
            series_id INTEGER REFERENCES series(id),
            season INTEGER DEFAULT 1,
            episode_number INTEGER NOT NULL,
            telegram_message_id INTEGER UNIQUE NOT NULL,
            telegram_channel_id VARCHAR(255),
            added_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """))
    conn.execute(text("CREATE INDEX IF NOT EXISTS idx_series_normalized_name ON series(normalized_name)"))
    conn.execute(text("CREATE UNIQUE INDEX IF NOT EXISTS idx_episodes_msg_id ON episodes(telegram_message_id)"))
    conn.execute(text("CREATE INDEX IF NOT EXISTS idx_episodes_channel_id ON episodes(telegram_channel_id)"))
    conn.execute(text("CREATE INDEX IF NOT EXISTS idx_episodes_added_at ON episodes(added_at)"))
logger.info("âœ… Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø¬Ø§Ù‡Ø²Ø©")

# ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ù‚ÙŠØ³Ø© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© (Ø¥Ù† ÙˆØ¬Ø¯Øª)
with engine.begin() as conn:
    rows = conn.execute(text("SELECT id, name FROM series WHERE normalized_name IS NULL")).fetchall()
    for row in rows:
        norm = normalize_series_name(row[1])
        conn.execute(text("UPDATE series SET normalized_name = :norm WHERE id = :id"), {"norm": norm, "id": row[0]})
    if rows:
        logger.info(f"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« {len(rows)} Ø§Ø³Ù…Ø§Ù‹ Ù…Ù‚ÙŠØ³Ø§Ù‹")

# ------------------------------
# Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ ÙˆØ§Ù„ØªØ·Ø¨ÙŠØ¹
# ------------------------------
def normalize_arabic(text):
    if not text:
        return ''
    text = unicodedata.normalize('NFKD', text)
    text = re.sub(r'[\u064B-\u065F]', '', text)
    text = text.replace('Ø¥', 'Ø§').replace('Ø£', 'Ø§').replace('Ø¢', 'Ø§').replace('Ù‰', 'Ø§')
    text = text.replace('Ø©', 'Ù‡')
    return text

def normalize_series_name(name):
    if not name:
        return ''
    name = re.sub(r'^(Ù…Ø³Ù„Ø³Ù„|ÙÙŠÙ„Ù…)\s+', '', name, flags=re.UNICODE)
    name = re.sub(r'\s+(Ø§Ù„Ø­Ù„Ù‚Ø©|Ø§Ù„Ù…ÙˆØ³Ù…|Ø§Ù„Ø¬Ø²Ø¡)$', '', name, flags=re.UNICODE)
    name = re.sub(r'\s+\d+$', '', name)
    name = normalize_arabic(name)
    name = re.sub(r'\s+', ' ', name).strip().lower()
    return name

def clean_name_for_series(name):
    name = re.sub(r'^Ù…Ø³Ù„Ø³Ù„\s+', '', name, flags=re.UNICODE)
    name = re.sub(r'\s+(Ø§Ù„Ø­Ù„Ù‚Ø©|Ø§Ù„Ù…ÙˆØ³Ù…)$', '', name, flags=re.UNICODE)
    name = re.sub(r'\s+\d+$', '', name)
    name = re.sub(r'\s+', ' ', name).strip()
    return name

def clean_name_for_movie(name):
    name = re.sub(r'^ÙÙŠÙ„Ù…\s+', '', name, flags=re.UNICODE)
    name = re.sub(r'\s+Ø§Ù„Ø¬Ø²Ø¡\s*\d*$', '', name, flags=re.UNICODE)
    name = re.sub(r'\s+\d+$', '', name)
    name = re.sub(r'\s+', ' ', name).strip()
    return name

# ------------------------------
# Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø³Ù„Ø³Ù„Ø§Øª Ù„ÙƒÙ„ Ù‚Ù†Ø§Ø©
# ------------------------------
series_context = defaultdict(lambda: None)

# ------------------------------
# Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© (Ù…Ø¹Ø¯Ù„Ø© Ù„ØªØ¬Ù†Ø¨ ØªØ¹Ø§Ø±Ø¶ Ø§Ù„Ø§Ø³Ù… Ù…Ø¹ Ø¯Ø§Ù„Ø© SQLAlchemy text)
# ------------------------------
def parse_content_info(msg_text, channel_id, has_video):
    """
    ØªØ­Ù„ÙŠÙ„ Ù†Øµ Ø§Ù„Ø±Ø³Ø§Ù„Ø©.
    - Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ÙÙŠØ¯ÙŠÙˆ: Ù†Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª (Ù…Ø³Ù„Ø³Ù„/ÙÙŠÙ„Ù…).
    - Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ ÙÙŠØ¯ÙŠÙˆ: Ù†Ø®Ø²Ù† Ø§Ù„Ø§Ø³Ù… ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ¨Ø¯Ùˆ ÙƒØ§Ø³Ù… Ù…Ø³Ù„Ø³Ù„.
    """
    if not msg_text:
        return None, None, None, None

    msg_text = msg_text.strip()
    lower_text = msg_text.lower()

    # ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©
    series_keywords = ['Ø­Ù„Ù‚Ø©', 'Ø§Ù„Ø­Ù„Ù‚Ø©', 'Ù…ÙˆØ³Ù…', 'Ø§Ù„Ù…ÙˆØ³Ù…', 'season', 'episode']
    movie_keywords = ['ÙÙŠÙ„Ù…', 'Ø§Ù„Ø¬Ø²Ø¡', 'part']

    # ØªØ­Ø¯ÙŠØ¯ ÙˆØ¬ÙˆØ¯ ÙƒÙ„Ù…Ø§Øª Ù…Ø³Ù„Ø³Ù„/ÙÙŠÙ„Ù…
    is_series_word = 'Ù…Ø³Ù„Ø³Ù„' in lower_text
    is_movie_word = 'ÙÙŠÙ„Ù…' in lower_text

    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ÙÙŠØ¯ÙŠÙˆ
    if has_video:
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ù„Ø³Ù„ Ø¨Ø£Ù†Ù…Ø§Ø·Ù‡
        # 1. Ø§Ø³Ù… + Ø§Ù„Ù…ÙˆØ³Ù… X + Ø§Ù„Ø­Ù„Ù‚Ø© Y
        match = re.search(r'^(.*?)\s+Ø§Ù„Ù…ÙˆØ³Ù…\s+(\d+)\s+Ø§Ù„Ø­Ù„Ù‚Ø©\s+(\d+)$', msg_text, re.UNICODE)
        if match:
            name = clean_name_for_series(match.group(1))
            season = int(match.group(2))
            episode = int(match.group(3))
            return name, 'series', season, episode

        # 2. Ø§Ø³Ù… + SXE
        match = re.search(r'^(.*?)\s+[Ss](\d+)[Ee](\d+)$', msg_text)
        if match:
            name = clean_name_for_series(match.group(1))
            season = int(match.group(2))
            episode = int(match.group(3))
            return name, 'series', season, episode

        # 3. Ø§Ø³Ù… + Ø§Ù„Ø­Ù„Ù‚Ø© X Ù…Ù† Ø§Ù„Ù…ÙˆØ³Ù… Y
        match = re.search(r'^(.*?)\s+Ø§Ù„Ø­Ù„Ù‚Ø©\s+(\d+)\s+Ù…Ù†\s+Ø§Ù„Ù…ÙˆØ³Ù…\s+(\d+)$', msg_text, re.UNICODE)
        if match:
            name = clean_name_for_series(match.group(1))
            episode = int(match.group(2))
            season = int(match.group(3))
            return name, 'series', season, episode

        # 4. Ø§Ø³Ù… + Ø§Ù„Ù…ÙˆØ³Ù… X - Y (Ø­Ù„Ù‚Ø©)
        match = re.search(r'^(.*?)\s+Ø§Ù„Ù…ÙˆØ³Ù…\s+(\d+)[-\s]+(\d+)$', msg_text, re.UNICODE)
        if match:
            name = clean_name_for_series(match.group(1))
            season = int(match.group(2))
            episode = int(match.group(3))
            return name, 'series', season, episode

        # 5. Ø§Ø³Ù… + Ø§Ù„Ø­Ù„Ù‚Ø© X (Ø¨Ø¯ÙˆÙ† Ù…ÙˆØ³Ù… -> Ù…ÙˆØ³Ù… 1)
        match = re.search(r'^(.*?)\s+Ø§Ù„Ø­Ù„Ù‚Ø©\s+(\d+)$', msg_text, re.UNICODE)
        if match:
            name = clean_name_for_series(match.group(1))
            episode = int(match.group(2))
            return name, 'series', 1, episode

        # 6. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø© "ÙÙŠÙ„Ù…" ØµØ±Ø§Ø­Ø©
        if is_movie_word or any(kw in lower_text for kw in movie_keywords):
            # ÙÙŠÙ„Ù… Ø¨Ø£Ù†Ù…Ø§Ø·Ù‡
            match = re.search(r'ÙÙŠÙ„Ù…\s+(.+?)\s+Ø§Ù„Ø¬Ø²Ø¡\s+(\d+)', msg_text, re.UNICODE)
            if match:
                name = clean_name_for_movie(match.group(1))
                part = int(match.group(2))
                return name, 'movie', part, 1
            match = re.search(r'ÙÙŠÙ„Ù…\s+(.+?)\s+(\d+)$', msg_text, re.UNICODE)
            if match:
                name = clean_name_for_movie(match.group(1))
                part = int(match.group(2))
                return name, 'movie', part, 1
            # ÙÙŠÙ„Ù… Ø¨Ø¯ÙˆÙ† Ø±Ù‚Ù…
            name = clean_name_for_movie(re.sub(r'ÙÙŠÙ„Ù…', '', msg_text, flags=re.UNICODE))
            return name, 'movie', 1, 1

        # 7. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ ÙŠØªÙƒÙˆÙ† Ø£Ø³Ø§Ø³Ù‹Ø§ Ù…Ù† Ø£Ø±Ù‚Ø§Ù… (Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø­Ù„Ù‚Ø© Ù…Ù† Ù…Ø³Ù„Ø³Ù„ Ø³Ø§Ø¨Ù‚)
        numbers = re.findall(r'\d+', msg_text)
        if numbers and series_context[channel_id] is not None:
            # ÙŠÙˆØ¬Ø¯ Ø³ÙŠØ§Ù‚ Ù…Ø³Ù„Ø³Ù„ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù‚Ù†Ø§Ø©
            if len(numbers) >= 2:
                season = int(numbers[0])
                episode = int(numbers[1])
            else:
                season = 1
                episode = int(numbers[0])
            logger.debug(f"Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø³ÙŠØ§Ù‚: {series_context[channel_id]} - Ù…{season} Ø­{episode}")
            return series_context[channel_id], 'series', season, episode

        # 8. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø© "Ù…Ø³Ù„Ø³Ù„" (Ø­ØªÙ‰ Ø¨Ø¯ÙˆÙ† ÙƒÙ„Ù…Ø§Øª Ø­Ù„Ù‚Ø©/Ù…ÙˆØ³Ù…)
        if is_series_word:
            name = clean_name_for_series(msg_text)
            return name, 'series', 1, 1

        # 9. Ù†Øµ Ø¹Ø§Ø¯ÙŠ ÙŠÙ†ØªÙ‡ÙŠ Ø¨Ø±Ù‚Ù… (Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø¬Ø²Ø¡ Ù…Ù† Ù…Ø³Ù„Ø³Ù„)
        # Ù†ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ù…Ø³Ù„Ø³Ù„ Ø¨Ù†ÙØ³ Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        base_name = re.sub(r'\s+\d+$', '', msg_text).strip()
        if base_name and base_name != msg_text:
            # Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¹Ù† ÙˆØ¬ÙˆØ¯ Ù…Ø³Ù„Ø³Ù„ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
            with engine.connect() as conn:
                exists = conn.execute(
                    text("SELECT 1 FROM series WHERE name ILIKE :pat AND type='series' LIMIT 1"),
                    {"pat": f"%{base_name}%"}
                ).scalar()
            if exists:
                # ÙŠÙˆØ¬Ø¯ Ù…Ø³Ù„Ø³Ù„ Ù…Ø´Ø§Ø¨Ù‡ØŒ Ù†ØµÙ†ÙÙ‡Ø§ ÙƒØ­Ù„Ù‚Ø©
                name = clean_name_for_series(base_name)
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±Ù‚Ù… Ù…Ù† Ø§Ù„Ù†Ù‡Ø§ÙŠØ©
                num_match = re.search(r'(\d+)$', msg_text)
                if num_match:
                    episode = int(num_match.group(1))
                    return name, 'series', 1, episode

        # 10. Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹ØŒ Ù†Ø¹ØªØ¨Ø±Ù‡ ÙÙŠÙ„Ù…
        name = clean_name_for_movie(msg_text)
        return name, 'movie', 1, 1

    # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ ÙÙŠØ¯ÙŠÙˆ (Ø¨ÙˆØ³Øª Ù†ØµÙŠ ÙÙ‚Ø·)
    else:
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ù„Ø­Ù„Ù‚Ø§ØªØŒ Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ø³Ù… Ù…Ø³Ù„Ø³Ù„ Ø¬Ø¯ÙŠØ¯
        if not any(kw in lower_text for kw in series_keywords + movie_keywords):
            # Ù†Ø¹ØªØ¨Ø±Ù‡ Ø§Ø³Ù…Ø§Ù‹ Ù„Ù…Ø³Ù„Ø³Ù„ (Ø£Ùˆ ÙÙŠÙ„Ù…) Ø³ÙŠØ¸Ù‡Ø± Ù„Ø§Ø­Ù‚Ø§Ù‹
            if is_series_word or (not is_movie_word and not re.search(r'\d', msg_text)):
                name = clean_name_for_series(msg_text)
                if name:
                    series_context[channel_id] = name
                    logger.info(f"ğŸ“ ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø³ÙŠØ§Ù‚ Ù…Ø³Ù„Ø³Ù„: {name} ÙÙŠ {channel_id}")
            # Ù„Ø§ Ù†Ø±Ø¬Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø£Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¨ÙˆØ³Øª Ù„ÙŠØ³ Ù„Ù‡ ÙÙŠØ¯ÙŠÙˆ
        return None, None, None, None

# ------------------------------
# Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù‚Ù†ÙˆØ§Øª
# ------------------------------
async def get_channel_entity(client, channel_input):
    try:
        return await client.get_entity(channel_input)
    except Exception as e:
        logger.warning(f"âš ï¸ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ÙˆØµÙˆÙ„ {channel_input}: {e}")
        if isinstance(channel_input, str) and channel_input.startswith('https://t.me/+'):
            try:
                invite = channel_input.split('+')[-1]
                await client(ImportChatInviteRequest(invite))
                return await client.get_entity(channel_input)
            except:
                return None
        return None

def save_to_database(name, content_type, season, episode, msg_id, channel_id):
    try:
        with engine.begin() as conn:
            normalized = normalize_series_name(name)
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø³Ù„Ø³Ù„
            row = conn.execute(
                text("SELECT id FROM series WHERE normalized_name = :norm AND type = :typ"),
                {"norm": normalized, "typ": content_type}
            ).fetchone()
            if not row:
                # Ø¨Ø­Ø« Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ILIKE (Ø£ÙˆÙ„ 3 ÙƒÙ„Ù…Ø§Øª)
                words = name.split()[:3]
                if words:
                    like = '%' + '%'.join(words) + '%'
                    row = conn.execute(
                        text("SELECT id FROM series WHERE name ILIKE :pat AND type = :typ LIMIT 1"),
                        {"pat": like, "typ": content_type}
                    ).fetchone()
            if not row:
                # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙŠØ¯
                row = conn.execute(
                    text("INSERT INTO series (name, normalized_name, type) VALUES (:name, :norm, :typ) RETURNING id"),
                    {"name": name, "norm": normalized, "typ": content_type}
                ).fetchone()
            sid = row[0]

            # Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„Ø­Ù„Ù‚Ø©
            inserted = conn.execute(
                text("""
                    INSERT INTO episodes (series_id, season, episode_number, telegram_message_id, telegram_channel_id)
                    VALUES (:sid, :season, :ep, :msg, :chan)
                    ON CONFLICT (telegram_message_id) DO NOTHING
                    RETURNING id
                """),
                {"sid": sid, "season": season, "ep": episode, "msg": msg_id, "chan": channel_id}
            ).fetchone()
            if inserted:
                logger.info(f"âœ… Ø¬Ø¯ÙŠØ¯: {name} - Ù…{season} Ø­{episode} Ù…Ù† {channel_id}")
                return True
            else:
                logger.debug(f"âš ï¸ Ù…ÙˆØ¬ÙˆØ¯Ø©: {msg_id}")
                return False
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ÙØ¸: {e}")
        return False

def delete_from_database(msg_id):
    try:
        with engine.begin() as conn:
            ep = conn.execute(
                text("SELECT series_id FROM episodes WHERE telegram_message_id = :msg"),
                {"msg": msg_id}
            ).fetchone()
            if not ep:
                return False
            sid = ep[0]
            conn.execute(text("DELETE FROM episodes WHERE telegram_message_id = :msg"), {"msg": msg_id})
            remaining = conn.execute(
                text("SELECT COUNT(*) FROM episodes WHERE series_id = :sid"),
                {"sid": sid}
            ).scalar()
            if remaining == 0:
                conn.execute(text("DELETE FROM series WHERE id = :sid"), {"sid": sid})
                logger.info(f"ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ø³Ù„Ø³Ù„ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ (Ø¢Ø®Ø± Ø­Ù„Ù‚Ø© {msg_id})")
            else:
                logger.info(f"ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ø­Ù„Ù‚Ø© {msg_id}")
            return True
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­Ø°Ù: {e}")
        return False

def clean_orphan_series():
    """Ø­Ø°Ù Ø§Ù„Ù…Ø³Ù„Ø³Ù„Ø§Øª/Ø§Ù„Ø£ÙÙ„Ø§Ù… Ø§Ù„ØªÙŠ Ù„ÙŠØ³ Ù„Ù‡Ø§ Ø£ÙŠ Ø­Ù„Ù‚Ø§Øª (ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ Ù…Ù† Ø¨ÙˆØ³Øª ØªØ¹Ø±ÙŠÙ ÙˆÙ„Ù… ØªØ£ØªÙ Ø­Ù„Ù‚Ø§Øª)"""
    try:
        with engine.begin() as conn:
            result = conn.execute(text("""
                DELETE FROM series
                WHERE id NOT IN (SELECT DISTINCT series_id FROM episodes)
                RETURNING id, name, type
            """)).fetchall()
            if result:
                for r in result:
                    logger.info(f"ğŸ§¹ ØªÙ… Ø­Ø°Ù {r[2]} Ø¨Ø¯ÙˆÙ† Ø­Ù„Ù‚Ø§Øª: {r[1]} (ID: {r[0]})")
                logger.info(f"âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ {len(result)} Ù…Ø³Ù„Ø³Ù„/ÙÙŠÙ„Ù… Ø¨Ø¯ÙˆÙ† Ø­Ù„Ù‚Ø§Øª")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„ÙŠØªÙŠÙ…Ø©: {e}")

def fix_misclassified_series():
    """
    ØªØµØ­ÙŠØ­ Ø§Ù„Ù…Ø³Ù„Ø³Ù„Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… ØªØµÙ†ÙŠÙÙ‡Ø§ Ø®Ø·Ø£ ÙƒØ£ÙÙ„Ø§Ù… (movie) ÙˆÙ„ÙƒÙ† Ù„Ø¯ÙŠÙ‡Ø§ Ø£ÙƒØ«Ø± Ù…Ù† Ø­Ù„Ù‚Ø©.
    Ù†Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ series type='movie' Ù„Ø¯ÙŠÙ‡ Ø¹Ø¯Ø© Ø­Ù„Ù‚Ø§ØªØŒ ÙˆÙ†Ø­ÙˆÙ„ type Ø¥Ù„Ù‰ 'series'.
    """
    try:
        with engine.begin() as conn:
            # Ù†Ø¬Ø¯ Ø§Ù„Ø£ÙÙ„Ø§Ù… Ø§Ù„ØªÙŠ Ù„Ø¯ÙŠÙ‡Ø§ Ø£ÙƒØ«Ø± Ù…Ù† Ø­Ù„Ù‚Ø©
            rows = conn.execute(text("""
                SELECT s.id, s.name, COUNT(e.id) as ep_count
                FROM series s
                JOIN episodes e ON s.id = e.series_id
                WHERE s.type = 'movie'
                GROUP BY s.id, s.name
                HAVING COUNT(e.id) > 1
            """)).fetchall()
            if rows:
                for row in rows:
                    sid, name, count = row
                    conn.execute(
                        text("UPDATE series SET type = 'series' WHERE id = :sid"),
                        {"sid": sid}
                    )
                    logger.info(f"ğŸ”„ ØªÙ… ØªØµØ­ÙŠØ­ {name} (ID: {sid}) Ù…Ù† ÙÙŠÙ„Ù… Ø¥Ù„Ù‰ Ù…Ø³Ù„Ø³Ù„ (Ù„Ø¯ÙŠÙ‡ {count} Ø­Ù„Ù‚Ø§Øª)")
                logger.info(f"âœ… ØªÙ… ØªØµØ­ÙŠØ­ {len(rows)} Ù…Ø³Ù„Ø³Ù„ ÙƒØ§Ù† Ù…ØµÙ†Ù Ø®Ø·Ø£ ÙƒÙÙŠÙ„Ù…")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØµØ­ÙŠØ­ Ø§Ù„ØªØµÙ†ÙŠÙ: {e}")

# ------------------------------
# Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù‚Ù†ÙˆØ§Øª
# ------------------------------
async def sync_channel_messages(client, channel):
    chan_id = f"@{channel.username}" if channel.username else str(channel.id)
    logger.info(f"\nğŸ”„ Ù…Ø²Ø§Ù…Ù†Ø© {channel.title} ({chan_id})")

    # Ø¬Ù„Ø¨ Ø¢Ø®Ø± 1000 Ø±Ø³Ø§Ù„Ø©
    messages = []
    async for msg in client.iter_messages(channel, limit=1000):
        if msg.text:
            messages.append(msg)
    messages.reverse()  # Ø£Ù‚Ø¯Ù… Ø£ÙˆÙ„Ø§Ù‹ Ù„Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø³ÙŠØ§Ù‚

    # Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ù…Ø®Ø²Ù†Ø©
    with engine.connect() as conn:
        stored = conn.execute(
            text("SELECT telegram_message_id FROM episodes WHERE telegram_channel_id = :chan"),
            {"chan": chan_id}
        ).fetchall()
    stored_set = {r[0] for r in stored}

    new = 0
    skipped = 0
    failed = 0

    for msg in messages:
        if msg.id in stored_set:
            skipped += 1
            continue

        has_video = msg.video or (msg.document and msg.document.mime_type and msg.document.mime_type.startswith('video/'))
        name, typ, season, ep = parse_content_info(msg.text, chan_id, has_video)

        if name and typ and ep and has_video:
            if save_to_database(name, typ, season, ep, msg.id, chan_id):
                new += 1
                stored_set.add(msg.id)
            else:
                # ÙØ´Ù„ - ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯Ù‡Ø§
                with engine.connect() as conn2:
                    exists = conn2.execute(
                        text("SELECT 1 FROM episodes WHERE telegram_message_id = :mid"),
                        {"mid": msg.id}
                    ).scalar()
                    if exists:
                        skipped += 1
                    else:
                        failed += 1
                        logger.error(f"âŒ ÙØ´Ù„ Ø¥Ø¯Ø±Ø§Ø¬ {msg.id}")
        else:
            if not has_video:
                logger.debug(f"ğŸ“ Ø±Ø³Ø§Ù„Ø© ØªØ¹Ø±ÙŠÙ (Ø¨Ø¯ÙˆÙ† ÙÙŠØ¯ÙŠÙˆ): {msg.id}")
            else:
                failed += 1

    logger.info(f"âœ… {channel.title}: {new} Ø¬Ø¯ÙŠØ¯Ø©, {skipped} Ù…ÙˆØ¬ÙˆØ¯Ø©, {failed} ÙØ´Ù„")

async def import_channel_history(client, channel):
    chan_id = f"@{channel.username}" if channel.username else str(channel.id)
    logger.info(f"\nğŸ“‚ Ø§Ø³ØªÙŠØ±Ø§Ø¯ ÙƒØ§Ù…Ù„ {channel.title}")
    all_msgs = []
    async for msg in client.iter_messages(channel, limit=None):
        if msg.text:
            all_msgs.append(msg)
    all_msgs.reverse()
    logger.debug(f"ğŸ“Š {len(all_msgs)} Ø±Ø³Ø§Ù„Ø©")

    with engine.connect() as conn:
        stored = conn.execute(
            text("SELECT telegram_message_id FROM episodes WHERE telegram_channel_id = :chan"),
            {"chan": chan_id}
        ).fetchall()
    stored_set = {r[0] for r in stored}

    new = 0
    skipped = 0
    failed = 0

    for msg in all_msgs:
        if msg.id in stored_set:
            skipped += 1
            continue

        has_video = msg.video or (msg.document and msg.document.mime_type and msg.document.mime_type.startswith('video/'))
        name, typ, season, ep = parse_content_info(msg.text, chan_id, has_video)

        if name and typ and ep and has_video:
            if save_to_database(name, typ, season, ep, msg.id, chan_id):
                new += 1
                stored_set.add(msg.id)
            else:
                with engine.connect() as conn2:
                    exists = conn2.execute(
                        text("SELECT 1 FROM episodes WHERE telegram_message_id = :mid"),
                        {"mid": msg.id}
                    ).scalar()
                    if exists:
                        skipped += 1
                    else:
                        failed += 1
                        logger.error(f"âŒ ÙØ´Ù„ Ø¥Ø¯Ø±Ø§Ø¬ {msg.id}")
        else:
            if not has_video:
                logger.debug(f"ğŸ“ Ø±Ø³Ø§Ù„Ø© ØªØ¹Ø±ÙŠÙ: {msg.id}")
            else:
                failed += 1

    logger.info(f"ğŸ“¥ {channel.title}: {new} Ø¬Ø¯ÙŠØ¯Ø©, {skipped} Ù…ÙˆØ¬ÙˆØ¯Ø©, {failed} ÙØ´Ù„")

async def check_deleted_messages(client, channel):
    chan_id = f"@{channel.username}" if channel.username else str(channel.id)
    logger.info(f"\nğŸ” ÙØ­Øµ Ø§Ù„Ù…Ø­Ø°ÙˆÙØ§Øª ÙÙŠ {channel.title}")
    try:
        with engine.connect() as conn:
            stored = conn.execute(
                text("SELECT telegram_message_id FROM episodes WHERE telegram_channel_id = :chan"),
                {"chan": chan_id}
            ).fetchall()
        stored_ids = [r[0] for r in stored]
        if not stored_ids:
            return
        current_ids = []
        async for msg in client.iter_messages(channel, limit=1000):
            current_ids.append(msg.id)
        deleted = [sid for sid in stored_ids if sid not in current_ids]
        if deleted:
            logger.info(f"ğŸ—‘ï¸ {len(deleted)} Ø±Ø³Ø§Ù„Ø© Ù…Ø­Ø°ÙˆÙØ©")
            for mid in deleted:
                delete_from_database(mid)
        else:
            logger.info("âœ… Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø­Ø°ÙˆÙØ§Øª")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙØ­Øµ: {e}")

# ------------------------------
# Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# ------------------------------
async def monitor_channels():
    logger.info(f"Ù…Ø±Ø§Ù‚Ø¨Ø© {len(CHANNEL_LIST)} Ù‚Ù†Ø§Ø©")
    client = TelegramClient(StringSession(STRING_SESSION), API_ID, API_HASH)
    await client.start()
    logger.info("âœ… Ù…ØªØµÙ„ Ø¨Ù€ Telegram")

    channels = []
    for inp in CHANNEL_LIST:
        ch = await get_channel_entity(client, inp)
        if ch:
            channels.append(ch)
            logger.info(f"âœ… {ch.title}")
    if not channels:
        logger.error("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚Ù†ÙˆØ§Øª ØµØ§Ù„Ø­Ø©")
        return

    # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø³ÙŠØ§Ù‚
    global series_context
    series_context.clear()

    # Ù…Ø²Ø§Ù…Ù†Ø© Ø£ÙˆÙ„ÙŠØ©
    for ch in channels:
        await sync_channel_messages(client, ch)

    # Ø§Ø³ØªÙŠØ±Ø§Ø¯ ÙƒØ§Ù…Ù„ Ø¥Ø°Ø§ Ù…ÙØ¹Ù„
    if IMPORT_HISTORY:
        for ch in channels:
            await import_channel_history(client, ch)

    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø³Ù„Ø³Ù„Ø§Øª Ø¨Ø¯ÙˆÙ† Ø­Ù„Ù‚Ø§Øª
    clean_orphan_series()

    # ØªØµØ­ÙŠØ­ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø®Ø§Ø·Ø¦ (Ù…Ø³Ù„Ø³Ù„Ø§Øª ÙÙŠ Ø§Ù„Ø£ÙÙ„Ø§Ù…)
    fix_misclassified_series()

    # ÙØ­Øµ Ø§Ù„Ù…Ø­Ø°ÙˆÙØ§Øª
    if CHECK_DELETED_MESSAGES:
        for ch in channels:
            await check_deleted_messages(client, ch)

    # Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø­Ø¯Ø§Ø«
    @client.on(events.NewMessage(chats=channels))
    async def handler(event):
        msg = event.message
        if msg.text:
            chan_id = f"@{msg.chat.username}" if msg.chat.username else str(msg.chat.id)
            has_video = msg.video or (msg.document and msg.document.mime_type and msg.document.mime_type.startswith('video/'))
            name, typ, season, ep = parse_content_info(msg.text, chan_id, has_video)
            if name and typ and ep and has_video:
                save_to_database(name, typ, season, ep, msg.id, chan_id)

    @client.on(events.MessageDeleted(chats=channels))
    async def delete_handler(event):
        for mid in event.deleted_ids:
            delete_from_database(mid)

    logger.info("ğŸ¯ ÙÙŠ Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ø£Ø­Ø¯Ø§Ø«...")
    await client.run_until_disconnected()

if __name__ == "__main__":
    asyncio.run(monitor_channels())
